#! /usr/bin/env python3
# -*- mode: Python; -*-

from itertools import groupby, count
from queue import Queue
from subprocess import Popen, PIPE, DEVNULL
from threading import Thread
import enum, os, re, sys, tempfile, traceback

from vrtargslib import trans_args, trans_main
from vrtargslib import BadData, BadCode

from vrtnamelib import binxname, binxrest
from vrtnamelib import binnamelist, nameindex, nameindices
from vrtnamelib import isbinnames as isnames, bininsertnames

from vrtdatalib import binasrecord
from vrtdatalib import binunescape as unescape
from vrtdatalib import binescape as escape

# The underlying thing is known variously as "mate tools" (though mate
# tools consist of other things, too), "anna" (for whatever
# motivation, nowhere to be found), apparently "is2", and "the parser"
# and certain other locutions that describe or praise the parser.

PARSER = [ 'java', '-cp',
           '/proj/kieli/varpunen/mate-tools/anna-3-1.jar',
           'is2.parser.Parser',
           '-model', '/proj/kieli/varpunen/models/parser.model',
           '-test', '/dev/stdin'

           # extend with [ '-out', pipename ] at the point of Popen,
           # when a named-pipe name is at hand, because this version
           # of this thing writes its *diagnostics* in its stdout
]

# Let slip the first "Processing Sentence: 1 (32 ms/instance)".
# Quash the hundred thousand "2 (113 ms/instance)" that follow.
BREAKER = [ '/usr/bin/tr', '-s', r'\b', r'\n' ] # sigh
QUASHER = [ '/bin/grep', '-P', '-x', '-v', r'\d+ \(\d+ ms/instance\)' ]

def parsearguments():
    description = '''

    Pass morphologically tagged word forms in a flat vrt document
    through the parser of Mate-Tools using the model from Turku.
    Insert the syntactic dependency analysis in new fields after the
    tag field. The vrt document must have position names in a comment
    before any content. (A "flat" vrt document has no markup or
    comment lines inside sentence elements.)

'''

    parser = trans_args(description = description)

    parser.add_argument('--word', '-w', metavar = 'name',
                        type = binxname, default = b'word',
                        help = 'input word-field name (default word)')
    parser.add_argument('--tag', '-t', metavar = 'name',
                        type = binxname, default = b'pos',
                        help = 'input pos-tag-field name (default pos)')
    parser.add_argument('--feat', '-f', metavar = 'name',
                        type = binxname, default = b'feat',
                        help = 'input feature-field name (default feat)')
    parser.add_argument('--prefix', '-p', metavar = 'fix',
                        type = binxname, default = b'',
                        help = 'prefix to output-field names')
    parser.add_argument('--suffix', '-s', metavar = 'fix',
                        type = binxrest, default = b'',
                        help = 'suffix to output-field names')

    group = parser.add_mutually_exclusive_group()
    group.add_argument('--quiet', '-q', action = 'store_true',
                       help = 'quash all diagnostics from the parser')
    group.add_argument('--verbose', '-v', action = 'store_true',
                       help = 'watch parser report on every sentence')

    parser.add_argument('--track', action = 'store_true',
                        help = '''

                        track execution in stderr (because termination
                        was even trickier to ensure than expected)

''')

    args = parser.parse_args()
    args.prog = parser.prog
    return args

def message(args, mess, *, track = False):
    if track:
        args.track and print(args.prog + ': --track:', mess,
                             file = sys.stderr, flush = True)
    else:
        print(args.prog + ':', mess,
              file = sys.stderr, flush = True)

def terminate(proc):
    try:
        proc.terminate()
    except ProcessLookupError:
        pass

def main(args, inf, ouf):
    message(args, 'entered main', track = True)
    
    temp = tempfile.mkdtemp(prefix = 'vrt.')
    pipename = os.path.join(temp, 'tdpalpha')
    os.mkfifo(pipename)

    message(args, 'created named pipe: {}'.format(pipename),
            track = True)

    # attempts to open the named pipe here stalled, regardless of
    # whether it was for reading or writing

    breaker = ( None
                if args.quiet else
                Popen(BREAKER, stdin = PIPE, stdout = sys.stderr.buffer)
                if args.verbose else
                Popen(BREAKER, stdin = PIPE, stdout = PIPE) )

    quasher = ( None
                if (args.quiet or args.verbose) else
                Popen(QUASHER,
                      stdin = breaker.stdout,
                      stdout = sys.stderr.buffer) )

    # an attempt to open the named pipe for reading *here* stalled

    # somewhere here should close some standard streams to have
    # eventual broken pipes have the intended effect, right? no?
    # breaker.stdout when it is the PIPE to quasher, presumably, not
    # sure but apparently not harmful at least:

    quasher is None or breaker.stdout.close()

    with Popen(PARSER + [ '-out', pipename ],
               stdin = PIPE,
               stdout = (breaker.stdin if breaker else DEVNULL),
               stderr = sys.stderr.buffer) as parser:



        # opening the named pipe *here* seems to succeed

        message(args, 'opening pipe for reading', track = True)
        pipe = open(pipename, mode = 'rb')
        message(args, 'opened pipe for reading', track = True)

        # combine reads pipe but on exception terminates parser
        # because merely closing pipe seemed to stall parser and
        # then stall write/flush attempts in main, requiring
        # keyboard interrupt (or other external signal) to
        # terminate the program

        copy = Queue()
        ( Thread(target = combine, args = (args, pipe, parser, copy, ouf))
          .start() )

        status = 1
        try:
            # raise Exception('testing termination')
            implement_main(args, inf, parser, copy)
            status = 0
        except BadData as exn:
            message(args, str(exn))
        except BrokenPipeError as exn:
            # when combine thread gets broken pipe, it closes the
            # output side of pipe and copy, then they close and
            # this thread gets broken pipe - right?
            message(args, 'broken pipe in main thread')
        except KeyboardInterrupt as exn:
            message(args, 'keyboard interrupt in main thread')
            message(args, traceback.format_exc(), track = True)
        except Exception as exn:
            message(args, traceback.format_exc())

        # this one closure may be
        # crucial for graceful
        # termination
        try:
            # so it was getting broken pipe *here* and then never
            # getting to terminate and join - did not expect this
            message(args, 'closing parser stdin in main', track = True)
            parser.stdin.close()
        except Exception as exn:
            message(args, 'while closing in main: ' + str(exn))

        if status:
            message(args, 'non-zero status: terminating subprocesses',
                    track = True)
            terminate(parser)
            # terminate(copy)
            breaker is None or terminate(breaker)
            quasher is None or terminate(quasher)

        message(args, 'joining copy', track = True)
        copy.join()
        message(args, 'joined copy', track = True)

        message(args, 'removing {}'.format(pipename), track = True)
        os.remove(pipename)
        os.rmdir(temp)

        message(args, 'returning from main', track = True)

        return status

def implement_main(args, inf, parser, copy):

    # each "word" and "tag" go to parser, with empty line after
    # sentence; everything goes to copy in reified groups of meta and
    # data, with new "id", "dephead", "deprel" (or such) in names

    idname = args.prefix + b'id' + args.suffix
    headname = args.prefix + b'head' + args.suffix
    relname = args.prefix + b'rel' + args.suffix

    wf, tf, ff = None, None, None # word, tag, feat positions
    # found = False
    def issome(line): return not line.isspace()
    def ismeta(line): return line.startswith(b'<')

    meta = None
    for groupismeta, group in groupby(filter(issome, inf), ismeta):

        if groupismeta:
            meta = list(group)
            for k, line in enumerate(meta):
                if isnames(line):
                    wf, tf, ff = nameindices(binnamelist(line),
                                             args.word,
                                             args.tag,
                                             args.feat)
                    meta[k] = bininsertnames(line, args.feat,
                                             idname,
                                             headname,
                                             relname)

            copy.put(meta)
            continue

        # groupisdata aka token lines

        if wf is None:
            raise BadData('no field names before positional data')

        # always have previous meta
        if meta is None: copy.put(())

        sentence = tuple(map(binasrecord, group))
        copy.put(sentence)

        for k, record in enumerate(sentence, start = 1):
            
            # print('DEBUG: sending token')
            # format for the whatever parser is CoNLL'09:
            # ID FORM LEMMA PLEMMA POS PPOS FEAT PFEAT
            # HEAD PHEAD DEPREL PDEPREL FILLPRED PRED APREDs
            # (er, any number of APRED1, APRED2, ...)
            # to guess where the input should be - ID, FORM,
            # POS, FEAT, right? but does the parser conform?

            # ID tab
            parser.stdin.write(str(k).encode('UTF-8'))
            parser.stdin.write(b'\t')
            # FORM tab LEMMA tab PLEMMA tab
            parser.stdin.write(unescape(record[wf]))
            parser.stdin.write(b'\t_\t_\t')
            # POS tab PPOS tab
            parser.stdin.write(unescape(record[tf]))
            parser.stdin.write(b'\t_\t')
            # FEAT tab PFEAT tab
            parser.stdin.write(unescape(record[ff]))
            parser.stdin.write(b'\t_\t')
            # HEAD tab PHEAD tab DEPREL tab PDEPREL tab
            parser.stdin.write(b'_\t_\t_\t_\t')
            # FILLPRED tab PRED nl
            parser.stdin.write(b'_\t_\n')
        else:
            parser.stdin.write(b'\n')
            parser.stdin.flush()

    else:
        # always have final meta
        groupismeta or copy.put(())

def combine(args, pipe, parser, copy, out):
    '''Read line-separated output groups from the named pipe where the
    parser process writes it. Read the corresponding input from the
    copy queue. Insert dependency analysis from parser to the input at
    the named position. Write the result out.

    This is run as a thread that consumes the parsing process through
    its named pipe, and the copy queue in step with it.

    '''

    message(args, 'enter combine', track = True)

    try:
        implement_combine(args, pipe, copy, out)
    except BrokenPipeError:
        message(args, 'broken pipe in combine thread')
    except StopIteration:
        # from next(response) when main thread got keyboard interruption
        message(args, 'stop iteration in combine thread')
    except ValueError as exn:
        # sometimes keyboard interruption in main thread produces here
        # a readline of closed file
        message(args, 'value error in combine thread:' + str(exn))
    except Exception as exn:
        message(args, traceback.format_exc())
    finally:
        # closing their stdouts should send parser (behind pipe) and
        # copy the signal to shut down, right? and then the main
        # thread should get broken pipe to indicate that it can no
        # longer write to them? but parser does not seem to propagate
        # the signal when it gets the signal and things stall
        try:
            message(args, 'terminating parser in combine', track = True)
            terminate(parser)
            # seems that parser does not terminate when it gets broken
            # pipe nor does it propagate the broken pipe to main that
            # then stalls writing to the parser - it just reports the
            # exception to stderr and stalls? - so this should
            # terminate parser instead: combine does need access!
        except Exception as exn:
            message(args, 'terminating parser in combine: ' + str(exn))
        finally:
            message(args, 'returning from combine', track = True)

def implement_combine(args, pipe, copy, out):

    analyses = (group
                for groupisspace, group
                in groupby(pipe, bytes.isspace)
                if not groupisspace)

    mf = None # msd field index, after which insert new

    for analysis in analyses:

        meta = copy.get_nowait()
        copy.task_done()

        for line in meta:
            out.write(line)
            if isnames(line):
                mf = nameindex(binnamelist(line), args.feat)

        if mf is None:
            raise BadData('no field names before positional data')

        data = copy.get_nowait()
        copy.task_done()

        for new, old in zip(analysis, data):
            [
                ID, form, lemma, plemma,
                pos, ppos, feat, pfeat,
                dephead, pdephead, deprel, pdeprel,
                fillpred, pred
            ] = binasrecord(new)
            old.insert(mf + 1, escape(pdeprel))
            old.insert(mf + 1, escape(pdephead))
            old.insert(mf + 1, escape(ID))
            out.write(b'\t'.join(old))
            out.write(b'\n')

    meta = copy.get()
    copy.task_done()
    for line in meta:
        out.write(line)

if __name__ == '__main__':
    trans_main(parsearguments(), main,
               in_as_text = False,
               out_as_text = False)
