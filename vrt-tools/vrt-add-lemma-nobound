#! /usr/bin/env python3
# -*- mode: Python; -*-


"""
vrt-add-lemma-noboundaries

Add lemmas without compound boundaries to the input VRT with word
forms and lemmas with compound boundaries.
"""


import re
import sys

from itertools import chain

import vrtdatalib
import vrtnamelib

from vrtargsoolib import InputProcessor


class NoBoundaryLemmaAdder(InputProcessor):

    DESCRIPTION = """
    Add lemmas without compound boundaries to the input VRT with word
    forms and lemmas with compound boundaries.
    """
    ARGSPECS = [
        ('--mode (*simple-omorfi|omorfi|naive)',
         'use the specified mode for handling compound boundary markers in'
         ' lemmas: "simple-omorfi" handles compound boundary markers replacing'
         ' hyphens as produced by Omorfi; "omorfi" also tries to handle'
         ' lemmatized non-final compound parts; and "naive" simply removes'
         ' all compound boundary markers (unless thw word form contains them)'),
        ('--compound-boundary-marker=CHAR "|" -> boundary_char',
         'treat CHAR as the compound boundary marker'),
        ('--no-fix-spurious-boundaries',
         'do not correct "#" to "|" if the word form contains as many "|" as'
         ' the lemma contains "#", to fix a deficiency in a UD1 parser;'
         ' note that even without this option, the character is corrected only'
         ' in the added lemma without compound boundaries and only if the'
         ' compound boundary marker is "#"'),
        ('--only-wordform-hyphens',
         """with --mode=omorfi, do not add a hyphen between same
         vowels at a compound boundary if the word form does not have
         it. Omorfi overgenerates compound boundaries so that the word
         form "ongelmaanne" may get the lemma "ongelma#anne" even
         though prescriptively, the word form should have been
         "ongelma-anne". By default, --mode=omorfi then produces the
         lemma "ongelma-anne", but with this option, "ongelmaanne".
         """),
        ('--wordform-name=ATTR "word" -> word_attr',
         'use positional attribute ATTR as the word form'),
        ('--lemma-name=ATTR "lemma" -> lemma_attr',
         'use positional attribute ATTR as the lemma'),
        ('--noboundaries-name=ATTR "lemma_nobound" -> nobound_attr',
         'output the lemma without boundaries as positional attribute ATTR'),
        ('--insert-noboundaries-after-name|insert-after=ATTR "lemma"'
         ' -> insert_after_attr',
         'insert the lemma without boundaries after positional attribute ATTR'),
        ('--verbose',
         'log output to stderr'),
    ]

    _lemma_suffix_len_changes = [('nen', -2)]
    # Stem changes that affect the second (and possibly first) letter
    _stem_changes = [
        ('ie', 'ei'),
        ('uo', 'oi'),
        ('yö', 'öi'),
        ('aika', 'aja'),
        ('aika', 'ajo'),
        ('apu', 'avu'),
        ('etu', 'edu'),
        ('hyvä', 'paras'),
        ('hyvä', 'parem'),
        ('hyvä', 'parha'),
        ('ikä', 'iä'),
        ('itu', 'idu'),
        ('oas', 'oka'),
        ('oka', 'oi'),
        ('ota', 'oda'),
        ('udar', 'utar'),
        ('uksi', 'ust'),
        ('ydin', 'ytim'),
        ('ei', 'em'),
        ('ei', 'en'),
        ('ei', 'et'),
    ]
    _vowels = 'aeiouyäö'
    # We would only need the second part if the first part can occur inflected
    # with some later part, such as "uudenkarhea", "uudenveroinen",
    # "vanhanmallinen". Another option might be to special-case them, as they
    # might be specific to certain later parts, such as "lainen", "puoleinen".
    # Capitalized (proper) nouns have been lowercased, as at least the UD1
    # variant of the Turku Dependency Parser Pipeline seems to lowercase some
    # of the lemmas ("tyynimeri").
    _inflected_first_part = {
        ('aava', 'meri'),
        ('hieno', 'sokeri'),
        # ('Iso', 'Britannia'),
        ('iso', 'britannia'),
        ('iso', 'jako'),
        ('iso', 'koskelo'),
        ('iso', 'kuovi'),
        ('iso', 'käpylintu'),
        ('iso', 'lepinkäinen'),
        ('iso', 'lokki'),
        ('iso', 'maksaruoho'),
        ('iso', 'masto'),
        ('iso', 'panda'),
        ('iso', 'pistooli'),
        ('iso', 'purje'),
        ('iso', 'rokko'),
        ('iso', 'rumpu'),
        ('iso', 'sisar'),
        ('iso', 'sisko'),
        ('isot', 'aivot'),
        ('iso', 'varvas'),
        ('iso', 'veli'),
        ('iso', 'viha'),
        ('karkea', 'rehu'),
        ('kevyt', 'sarja'),
        ('kirjava', 'pillike'),
        ('kuiva', 'kakku'),
        ('kuiva', 'kukka'),
        ('kuiva', 'muona'),
        ('kuiva', 'paino'),
        ('kuiva', 'pari'),
        ('kuiva', 'rehu'),
        ('kultainen', 'noutaja'),
        ('laiska', 'koira'),
        ('lämmin', 'ruoka'),
        ('lämmin', 'varasto'),
        ('lämmin', 'vaunu'),
        ('matala', 'meri'),
        ('musta', 'herukka'),
        ('musta', 'leipä'),
        ('musta', 'leski'),
        ('musta', 'lintu'),
        ('musta', 'maija'),
        ('musta', 'makkara'),
        # ('Musta', 'meri'),
        ('musta', 'meri'),
        ('musta', 'mies'),
        ('musta', 'multa'),
        ('musta', 'pekka'),
        ('musta', 'pippuri'),
        ('musta', 'raamattu'),
        ('musta', 'torvisieni'),
        ('musta', 'viinimarja'),
        ('nuori', 'emäntä'),
        ('nuori', 'herra'),
        ('nuori', 'isäntä'),
        ('nuori', 'karja'),
        ('nuori', 'mies'),
        ('nuori', 'pari'),
        ('oma', 'kuva'),
        ('oma', 'tunto'),
        ('paha', 'henki'),
        ('paha', 'putki'),
        ('palava', 'kivi'),
        ('palava', 'pensas'),
        ('palava', 'rakkaus'),
        ('pitkä', 'housu'),
        ('pitkä', 'kirkko'),
        ('pitkä', 'perjantai'),
        ('pitkä', 'piimä'),
        ('pitkä', 'siima'),
        ('pitkä', 'takki'),
        ('pitkät', 'housut'),
        # ('Punainen', 'meri'),
        ('punainen', 'meri'),
        ('puoli', 'kuu'),
        ('puoli', 'matka'),
        ('puoli', 'päivä'),
        ('puoli', 'väli'),
        ('puoli', 'yö'),
        ('raitis', 'ilma'),
        ('raskas', 'sarja'),
        ('raskas', 'vesi'),
        ('raskas', 'vety'),
        ('sepivä', 'peippi'),
        ('suora', 'kulma'),
        ('suora', 'ommel'),
        ('syvä', 'meri'),
        ('särkynyt', 'sydän'),
        ('tyhjä', 'paino'),
        # ('Tyyni', 'meri'),
        ('tyyni', 'meri'),
        ('täysi', 'kuu'),
        # ('Uusi', 'kaupunki'),
        ('uusi', 'kaupunki'),
        ('uusi', 'kuu'),
        # ('Uusi', 'maa'),
        ('uusi', 'maa'),
        # ('Uusi', 'Seelanti'),
        ('uusi', 'seelanti'),
        ('uusi', 'vuosi'),
        # ('Uusi', '*'),
        # Does this overgenerate?
        ('uusi', '*'),
        ('vanha', 'emäntä'),
        ('vanha', 'isäntä'),
        ('vanha', 'kaupunki'),
        ('vanha', 'piika'),
        ('vanha', 'poika'),
        ('vieras', 'mies'),
    }
    _adjust_case_fns = [
        (str.islower, str.lower),
        (str.isupper, str.upper),
        (str.istitle, str.title),
    ]

    def __init__(self):
        super().__init__()
        self._lemma_split_re = None
        self._lemma_split_keepsep_re = None
        self._omorfi_add_hyphens = False

    def main(self, args, inf, ouf):

        boundary_char = args.boundary_char.encode()
        fix_spurious_boundaries = (boundary_char == b'#'
                                   and not args.no_fix_spurious_boundaries)
        # Handle double boundary characters, which occur in for example
        # "neli||siipinen"
        self._lemma_split_re = re.compile('[' + args.boundary_char + '-]')
        self._lemma_split_keepsep_re = re.compile(
            '([' + args.boundary_char + '-]+)')
        self._omorfi_add_hyphens = not args.only_wordform_hyphens

        def make_lemma_noboundaries_simple(lemma, wordform):
            return lemma.replace(boundary_char, b'')

        # def log(before, kind, after):
        #     if args.verbose:
        #         print('#',
        #               *chain((w.decode().rstrip('\n')
        #                       for w in ([b'##'] + before)[-4:]),
        #                      [kind],
        #                      (w.decode().rstrip('\n')
        #                       for w in (after + [b'##'])[:6])),
        #               file=sys.stderr)

        def attr_index(s):
            """Convert numeric 1-based attribute index strings to 0-based ints,
            or return None for non-numeric."""
            try:
                return int(s) - 1
            except ValueError:
                return None

        LESS_THAN = '<'.encode()[0]
        if args.mode == 'omorfi':
            make_lemma_noboundaries = self._make_lemma_noboundaries_omorfi
        elif args.mode == 'naive':
            make_lemma_noboundaries = make_lemma_noboundaries_simple
        else:
            make_lemma_noboundaries = (
                self._make_lemma_noboundaries_omorfi_simple)
        for arg_name in ['word_attr', 'lemma_attr', 'nobound_attr',
                         'insert_after_attr']:
            setattr(args, arg_name, getattr(args, arg_name).encode())
        # print(args)
        word_index = attr_index(args.word_attr)
        lemma_index = attr_index(args.lemma_attr)
        insert_after_index = attr_index(args.insert_after_attr)
        if insert_after_index:
            insert_after_index += 1
        names_seen = False

        for line in inf:
            if line == b'\n':
                ouf.write(line)
            elif line[0] == LESS_THAN:
                if not names_seen and vrtnamelib.isbinnames(line):
                    word_index, lemma_index, insert_after_index = (
                        vrtnamelib.nameindices(vrtnamelib.binnamelist(line),
                                               args.word_attr,
                                               args.lemma_attr,
                                               args.insert_after_attr))
                    insert_after_index += 1
                    ouf.write(vrtnamelib.bininsertnames(
                        line, args.insert_after_attr, args.nobound_attr))
                else:
                    ouf.write(line)
            else:
                attrs = vrtdatalib.binasrecord(line)
                lemma = attrs[lemma_index]
                word = attrs[word_index]
                # If the word form contains a compound boundary marker, the
                # word is unlikely to be a real compound, so keep the lemma as
                # is.
                if boundary_char in lemma and not boundary_char in word:
                    # The Turku UD1 parser pipeline seems to convert literal
                    # |'s in lemmas to #'s if the wordform (and lemma) contains
                    # only punctuation characters
                    if (fix_spurious_boundaries
                            and lemma.count(boundary_char) == word.count(b'|')):
                        lemma_nobound = lemma.replace(boundary_char, b'|')
                    else:
                        lemma_nobound = make_lemma_noboundaries(lemma, word)
                else:
                    lemma_nobound = lemma
                ouf.write(b'\t'.join(chain(attrs[:insert_after_index],
                                           [lemma_nobound],
                                           attrs[insert_after_index:]))
                          + b'\n')

    def _make_lemma_noboundaries_omorfi_simple(self, lemma_b, wordform_b):
        # Adapted and slightly improved from vrt-fix-attrs.py
        # (PosAttrConverter._make_lemma_without_boundaries_tdt)
        lemma = lemma_b.decode()
        wordform = wordform_b.decode()
        boundary_char = self._args.boundary_char
        # If the boundary character is the first or the last in the lemma, it
        # should most likely be taken literally.
        if len(lemma) < 3 or boundary_char not in lemma[1:-1]:
            if (len(lemma) == 1 or boundary_char not in lemma
                    or (len(lemma) == 2 and lemma[0] == lemma[1])):
                return lemma_b
            # For example, "tuntinen" and "-tuntinen" get the lemma
            # "|tuntinen": in the first case, drop the boundary, in the second,
            # replace it with a hyphen.
            if lemma[0] == boundary_char:
                lemma = lemma[1:]
                if wordform[0] == '-':
                    lemma = '-' + lemma
            # Do trailing "|" occur?
            if lemma[-1] == boundary_char:
                lemma = lemma[:-1]
                if wordform[-1] == '-':
                    lemma += '-'
        elif '-' not in wordform:
            return lemma.replace(boundary_char, '').encode()
        # In some cases, the lemma has - replaced with a |; in
        # other cases not
        wordform_parts = wordform.split('-')
        lemma_parts = self._lemma_split_re.split(lemma)
        if (len(wordform_parts) == len(lemma_parts)
            and '-' not in lemma):
            return lemma.replace(boundary_char, '-').encode()
        else:
            lemma_without_boundaries = [lemma_parts[0]]
            lemma_prefix_len = len(lemma_parts[0])
            wf_prefix_len = len(wordform_parts[0])
            wf_partnr = 1
            for lemma_part in lemma_parts[1:]:
                if wf_partnr >= len(wordform_parts):
                    lemma_without_boundaries.append(lemma_part)
                elif (lemma_part[:2] == wordform_parts[wf_partnr][:2]
                      and abs(wf_prefix_len - lemma_prefix_len) <= 2):
                    # FIXME: Devise a better heuristic
                    lemma_without_boundaries.extend(['-', lemma_part])
                    wf_prefix_len += len(wordform_parts[wf_partnr])
                    wf_partnr += 1
                else:
                    lemma_without_boundaries.append(lemma_part)
                lemma_prefix_len += len(lemma_part)
            return ''.join(lemma_without_boundaries).encode()

    def _make_lemma_noboundaries_omorfi(self, lemma, wordform):
        # TODO: uudenvuoden -> uusivuosi
        lemma = lemma.decode()
        wordform = wordform.decode()
        lemma_parts = self._lemma_split_keepsep_re.split(lemma)
        wf_prefix_len = 0
        lemma_prefix_len = 0
        lemma_nobound = []
        for partnum, part in enumerate(lemma_parts[:-2]):
            if partnum % 2 == 0:
                # Actual compound part
                # FIXME: end_diff and wf_use_len are not currently
                # used, and _get_prefix does not return meaningful
                # values for them
                nobound_part, end_diff, wf_use_len = self._get_prefix(
                    lemma_parts[partnum], lemma_parts[partnum + 2],
                    wordform[wf_prefix_len:])
                # print(partnum, part, nobound_part, end_diff, wf_use_len)
                if (nobound_part and nobound_part[0] == '-'
                        and lemma_nobound and lemma_nobound[-1] == '-'):
                    nobound_part = nobound_part[1:]
                lemma_nobound.append(nobound_part)
                # print(nobound_part, lemma_parts, partnum, file=sys.stderr)
                # nobound_part may be empty if the lemma begins with a boundary
                # marker, which has replaced a hyphen ("|tuntinen"). This
                # replaces such a boundary marker with a hyphen; an alternative
                # would be to leave it out if the word form has no initial
                # hyphen.
                if (self._omorfi_add_hyphens
                        and nobound_part and nobound_part[-1] != '-'
                        and lemma_parts[partnum + 2]
                        and nobound_part[-1] == lemma_parts[partnum + 2][0]
                        and nobound_part[-1] in self._vowels):
                    lemma_nobound.append('-')
                wf_prefix_len += len(nobound_part)
        lemma_nobound.append(lemma_parts[-1])
        return (''.join(lemma_nobound)).encode()

    def _get_prefix(self, lemmapart_this, lemmapart_next, wordform):
        # yhteinen kunta yhteiskunnan -> yhteis, -2, 3
        # oleskella lupa oleskeluluvista ->
        # print('_get_prefix', lemmapart_this, lemmapart_next, wordform, file=sys.stderr)
        lemma_len = len(lemmapart_this)
        adjust_case_fn = lambda x: x
        for test_fn, adjust_fn in self._adjust_case_fns:
            if test_fn(lemmapart_this):
                adjust_case_fn = adjust_fn
                break

        def find_begin(lemmapart_next):
            for wf_prefix_len in range(min(len(lemmapart_next), 5), 1, -1):
                # print('CHECK:', wordform, lemmapart_next, wf_prefix_len, lemmapart_next[:wf_prefix_len], wordform[(lemma_len - 3):], file=sys.stderr)
                next_pos = find_next_begin(wf_prefix_len, lemmapart_next)
                if next_pos:
                    return (adjust_case_fn(wordform[:next_pos]),
                            next_pos - lemma_len,
                            wf_prefix_len)
            return None

        def find_next_begin(wf_prefix_len, lemmapart_next):
            # print('find_next_begin', wf_prefix_len, lemmapart_next, lemma_len, file=sys.stderr)
            begin_candidates = []
            start_pos = lemma_len - 3
            next_pos = 0
            while start_pos < lemma_len + 3 and next_pos > -1:
                # print('fnb loop:', wordform, lemmapart_next[:wf_prefix_len], start_pos, wordform[start_pos:], file=sys.stderr)
                next_pos = wordform.find(lemmapart_next[:wf_prefix_len],
                                         start_pos)
                # print('next_pos', next_pos, file=sys.stderr)
                check_len_right = 5 + (int(wordform[next_pos - 1] == '-')
                                       if next_pos > 0 else 0)
                if -1 < next_pos < lemma_len + check_len_right:
                    # print('FOUND:', wf_prefix_len, next_pos, lemmapart_next, wordform[:next_pos] + '[' + wordform[next_pos:(next_pos + wf_prefix_len)] + ']' + wordform[next_pos + wf_prefix_len:])
                    begin_candidates.append(next_pos)
                start_pos = next_pos + 1
            if not begin_candidates:
                return None
            elif len(begin_candidates) == 1:
                return begin_candidates[0]
            else:
                # If the current lemma part ends with a suffix for which a
                # length change has been specified and the first candidate for
                # the next part start begins at or before the lemma with the
                # length adjusted, prefer that (suomalainen|tuttu,
                # suomalais<tu><tu>t -> suomalaistuttu and not
                # suomalaistututtu)
                for suffix, len_change in self._lemma_suffix_len_changes:
                    if (lemmapart_this.endswith(suffix) and
                            begin_candidates[0] <= lemma_len + len_change):
                        return begin_candidates[0]
                # Otherwise, prefer the longest prefix (oleskella|lupa,
                # oleske<lu><lu>vista -> oleskelulupa and not oleskelupa)
                return begin_candidates[-1]

        # Are there other cases like ...toista, in which only the first part
        # inflects?
        if lemmapart_next.lower() == 'toista':
            return lemmapart_this, 0, len(lemmapart_this)
        hyphen_pos = wordform.find('-', max(0, lemma_len - 3), lemma_len + 4)
        # print(lemma_len, wordform, hyphen_pos, file=sys.stderr)
        maybe_hyphen = ('-' if hyphen_pos > -1 else '')
        lemmapart_this_lower = lemmapart_this.lower()
        if ((lemmapart_this_lower, lemmapart_next.lower())
                    in self._inflected_first_part
                or (lemmapart_this_lower, '*') in self._inflected_first_part):
            # print('INFL_FIRST', lemmapart_this + maybe_hyphen, 0,
            #       len(lemmapart_this), file=sys.stderr)
            return (lemmapart_this + maybe_hyphen, 0, len(lemmapart_this))
        # FIXME: Devise a better heuristic than comparing the two characters
        # following the hyphen with the two initial characters of the next
        # lemma part
        # Strip hyphen to cover cases like "bändi-T-paita"
        # print(hyphen_pos, len(wordform), len(lemmapart_next),
        #       wordform[hyphen_pos + 1:hyphen_pos + 3].strip('-'),
        #       lemmapart_next[:2])
        if (hyphen_pos > -1
                and (wordform[hyphen_pos + 1:hyphen_pos + 3].strip('-')
                     == lemmapart_next[:2])):
            # print('HYPHEN', adjust_case_fn(wordform[:(hyphen_pos + 1)]),
            #         hyphen_pos - lemma_len, 10, file=sys.stderr)
            return (adjust_case_fn(wordform[:(hyphen_pos + 1)]),
                    hyphen_pos - lemma_len, 10)
        return_vals = find_begin(lemmapart_next)
        if return_vals:
            return return_vals
        else:
            lemmapart_next_len = len(lemmapart_next)
            for lemma_stem, infl_stem in self._stem_changes:
                lemma_stem_len = len(lemma_stem)
                # print(lemma_stem, infl_stem, lemmapart_next_len, lemma_stem_len + 1, lemmapart_next.endswith(lemma_stem), file=sys.stderr)
                if (lemmapart_next_len <= lemma_stem_len + 1
                        and lemmapart_next.endswith(lemma_stem)):
                    return_vals = find_begin(
                        lemmapart_next[:(lemmapart_next_len - lemma_stem_len)]
                        + infl_stem)
                    if return_vals:
                        return return_vals
        # print('NOT FOUND')
        return lemmapart_this, 0, 0


if __name__ == '__main__':
    NoBoundaryLemmaAdder().run()
