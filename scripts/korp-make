#! /bin/bash
# -*- coding: utf-8 -*-


# TODO:
# - Allow specifying input via options (config file).
# - Option --force to force all stages.
# - Support corpora without parse attributes.
# - Allow different compound boundary options.
# - Allow multiple instances of extra file options to pass to
#   korp-make-corpus-package
# - Generate a VRT file containing all the added information.
# - Run stages based on checksums of previous stage's output.
# - Make multiple (related) corpora in the same package.
# - Make parallel corpora.


progname=`basename $0`
progdir=`dirname $0`

mapdir=$progdir/../corp

vrt_subdir=vrt/CORPUS
tsv_subdir=$vrt_subdir

usage_header="Usage: $progname [options] [corpus] [input_file ...]

Process a VRT file to make a Korp corpus package containing CWB data files and
MySQL database import files.

The corpus id must be specified either as the first non-option argument or via
the option --corpus-id.

The input files may be either (possibly compressed) VRT files containing
dependency parse information and name tags, or ZIP or (possibly compressed)
tar archives containing such VRT files. If no input files are specified, read
from the standard input."

optspecs='
corpus-id=CORPUS corpus
    make corpus with id CORPUS; this is alternative to specifying the
    corpus id as the first non-option argument
c|corpus-root=DIR "$corpus_root"
    use DIR as the root directory of corpus files
input-attrs|input-fields=ATTRS "ref lemma pos msd dephead deprel" initial_input_attrs
    specify the names of the positional attributes in the input,
    excluding the first one ("word" or token), separated by spaces
corpus-date=DATE
    use DATE as the date of all texts in the corpus; "unknown" if not
    known
corpus-date-pattern=PATTERN
    recognize corpus date information based on PATTERN of the form
    "ELEM ATTR REGEX": extract date information from the attribute
    ATTR of element (structural attribute) ELEM using the regular
    expression REGEX. ELEM and ATTR may be "*" (any element or
    attribute) or they may contain several attribute or element names
    separated with vertical bars. REGEX may contain named groups
    (subpatterns) in Python'"'"'s regular expressions Y, M and D,
    which extract year, month and day; for example, "(?:P<Y>[0-9]{4})"
    would recognize a year. REGEX may also cover both the start and
    end date, in which case the subpatterns for the start date are Y1,
    M1 and D1, and those for the end date, Y2, M2 and D2. If REGEX
    does not contain named subpatterns, recognize the first group as
    the start date and the possible second group as the end date.
corpus-date-full-order=ORDER
    recognize full dates in the order ORDER (one of "ymd", "dmy",
    "mdy")
corpus-date-ranges
    make the patterns recognize date ranges with different start and
    end days
lemgram-posmap|posmap=POSMAP_FILE "$mapdir/lemgram_posmap_tdt.tsv"
    use POSMAP_FILE as the mapping file from the corpus parts of
    speech to those used in Korp lemgrams; the file should contain
    lines with corpus POS and lemgram POS separated by a tab
wordpict-relmap|wordpicture-relation-map=RELMAP_FILE "$mapdir/wordpict_relmap_tdt.tsv"
    use RELMAP_FILE as the mapping file from corpus dependency
    relations to those used in the Korp word picture; the file
    should contain lines with corpus POS and lemgram POS
    separated by a tab
tsv-dir=DIR "$corpus_root/$tsv_subdir" tsvdir
    output database tables as TSV files to DIR
no-wordpicture|skip-wordpicture !wordpicture
    do not extract word picture relations database tables
no-name-attrs|no-name-attributes|skip-name-attrs|skip-name-attributes !name_attrs
    do not add named-entity information based on a NER tag as the last
    positional attribute
korp-frontend-dir=DIR "$korp_frontend_dir"
    read Korp configuration files from DIR, to be included in corpus
    package
package-readme-file|readme-file=FILE
    include FILE as a top-level read-me file in the corpus package;
    FILE may contain shell wildcards (but braces are not expanded)
package-doc-dir|doc-dir=DIR
    include DIR as a documentation directory "doc" in the corpus
    package
package-doc-file|doc-file=FILE
    include FILE as a documentation file in directory "doc" in the
    corpus package; FILE may contain shell wildcards
package-script-dir|script-dir=DIR
    include DIR as a (conversion) script directory "scripts" of
    the corpus package
package-script-file|script-file=FILE
    include FILE as a (conversion) script file in directory "scripts"
    of the corpus package; FILE may contain shell wildcards
package-extra-dir|extra-dir=SRCDIR[:DSTDIR]
    include directory SRCDIR in the corpus package; if :DSTDIR is
    specified, the directory is renamed as DSTDIR in the package
package-extra-file|extra-file=SRCFILE[:DSTFILE]
    include file SRCFILE in the corpus package; if :DSTFILE is
    specified, the file is renamed as DSTFILE in the package; if
    DSTFILE ends in a slash or if SRCFILE contains wildcards, DSTFILE
    is considered a directory name and SRCFILE is placed in that
    directory in the package
import-database
    import the database TSV files into the Korp MySQL database
v|verbose
    output some progress information
times show_times
    output the amount of CPU time used for each stage
config-file|configuration-file=FILE
    read FILE as an INI-style configuration file (without sections).
    Configuration keys correspond to option names without the leading
    dashes; internal dashes may be replaced with underscores.
log-file=FILE logfile
    log script output (standard output and standard error) to FILE
    instead of the default
    $corpus_root/log/${progname}_CORPUS_TIMESTAMP.log where CORPUS is
    the corpus id and TIMESTAMP the start time of the script
no-logging !logging
    do not copy script output to a log file
'

config_file_optname=config-file


. $progdir/korp-lib.sh

# cleanup_on_exit=


vrt_fix_attrs=$progdir/vrt-fix-attrs.py
vrt_add_lemgrams=$progdir/vrt-add-lemgrams.py
vrt_convert_chars=$progdir/vrt-convert-chars.py
vrt_extract_timespans=$progdir/vrt-extract-timespans.py
vrt_list_struct_attrs=$progdir/vrt-list-struct-attrs.py
korp_convert_timedata=$progdir/korp-convert-timedata.sh
cwbdata_extract_info=$progdir/cwbdata-extract-info.sh
vrt_extract_lemgrams=$progdir/vrt-extract-lemgrams.sh
run_extract_rels=$progdir/run-extract-rels.sh
vrt_add_name_attrs=$progdir/vrt-add-name-attrs.sh
korp_make_corpus_package=$progdir/korp-make-corpus-package.sh
korp_mysql_import=$progdir/korp-mysql-import.sh

cwb_encode=$cwb_bindir/cwb-encode
cwb_describe_corpus=$cwb_bindir/cwb-describe-corpus
cwb_make=$progdir/cwb-make-safe

vrt_file=


# Process options
eval "$optinfo_opt_handler"

if [ "x$corpus" = "x" ]; then
    if [ "x$1" = "x" ]; then
	error "No corpus name specified"
    fi
    corpus=$1
    shift
fi

if [ "x$logging" != x ]; then
    if [ "x$logfile" = x ]; then
	if [ ! -e "$corpus_root/log" ]; then
	    mkdir_perms $corpus_root/log
	fi
	logfile=$corpus_root/log/${progname}_${corpus}_$(date +'%Y%m%d%H%M%S').log
    fi
    # http://stackoverflow.com/questions/3173131/redirect-copy-of-stdout-to-log-file-from-within-bash-script-itself
    cat < /dev/null > $logfile
    ensure_perms $logfile
    exec > >(tee -ia $logfile)
    exec 2> >(tee -ia $logfile >&2)
    echo_verb "Logging output to $logfile"
fi

input_files=( "$@" )

vrtdir=${vrtdir:-$corpus_root/$vrt_subdir}
vrtdir=${vrtdir//CORPUS/$corpus}
tsvdir=${tsvdir:-$corpus_root/$tsv_subdir}
tsvdir=${tsvdir//CORPUS/$corpus}
datadir=$corpus_root/data/$corpus

mkdir_perms $vrtdir $tsvdir 2> /dev/null

if [ "x$vrt_file" = "x" ]; then
    vrt_file=$vrtdir/$corpus.vrt
fi

if [ "x$name_attrs" != x ] && ! word_in nertag "$initial_input_attrs"; then
    initial_input_attrs="$initial_input_attrs nertag"
fi
input_attrs=$initial_input_attrs
if ! word_in lemmacomp "$initial_input_attrs"; then
    input_attrs=${initial_input_attrs/lemma /lemma lemmacomp }
fi
if ! word_in lex/ "$initial_input_attrs"; then
    input_attrs="$initial_input_attrs lex/"
fi

verbose_opt=
if [ "x$verbose" != x ]; then
    verbose_opt=--verbose
fi


filter_new_attrs () {
    $cwb_describe_corpus -s $corpus > $tmp_prefix.corpusattrs 2> /dev/null
    if [ $? != 0 ]; then
	echo "$@"
    else
	awk '
	    BEGIN {
		for (i = 1; i < ARGC; i++) { attrs[i] = ARGV[i] }
		delete ARGV
	    }
	    /^p-ATT/ { old_attrs[$2] = 1 }
	    END {
		for (i in attrs) {
		    attrname_bare = gensub (/\//, "", "g", attrs[i])
		    # Lemma needs to be recoded as lemmacomp if lemmacomp is
		    # not already present
		    if (! (attrname_bare in old_attrs) \
			|| (attrname_bare == "lemma" \
			    && ! ("lemmacomp" in old_attrs))) {
			print attrs[i]
		    }
		}
	    }' $@ < $tmp_prefix.corpusattrs
    fi
}

new_attrs=$(filter_new_attrs "$input_attrs")


run_cmd () {
    verbose printf "  Running: " >&$top_stdout
    verbose echo_quoted "$@" >&$top_stdout
    "$@"
}

time_stage () {
    time_cmd --format "- CPU time used: %U %R" "$@"
}

# Run a single stage function (name) after printing the description
# (descr). If function test_skip_$name is defined and its output is
# non-empty, skip the stage.
run_stage () {
    local name=$1
    shift
    local descr="$@"
    local msg exitstat
    if type -t "test_skip_$name" > /dev/null; then
	msg=$(test_skip_$name 2> $tmp_prefix.errmsg)
	exitstat=$?
	# Exit with error if the test function (or the programs it
	# runs) outputs something to stderr. An alternative would be [
	# $? != 0 ], but that would require adding "return 0" to many
	# of the test_skip_ functions.
	if [ -s $tmp_prefix.errmsg ]; then
	    cat $tmp_prefix.errmsg
	    exit $exitstat
	fi
	if [ "x$msg" != "x" ]; then
	    echo_verb "(Skipping ${descr,}: $msg)"
	    return
	fi
    fi
    echo_verb "$descr"
    time_stage exit_on_error $name
}

# Run all the stages in $stages sequentially.
run_stages () {
    local stagecnt=${#stages[*]}
    local i=0
    while [ $i -lt $stagecnt ]; do
	run_stage ${stages[$i]} "${stages[$(($i + 1))]}"
	i=$(($i + 2))
    done
}


# Stage functions and their descriptions
stages=(
    add_new_attrs "Adding lemgrams and lemmas without compound boundaries"
    add_datefromto "Adding datefrom and dateto"
    cwb_encode "Encoding the attributes for CWB"
    cwb_make "Indexing and compressing the CWB data"
    convert_timedata "Converting and augmenting time data"
    extract_info "Extracting information for the .info file"
    extract_lemgrams "Extracting lemgrams for the database"
    extract_wordpict_rels
    "Extracting word picture relations for the database"
    add_name_attrs "Adding name attributes"
    make_corpus_package "Creating corpus package"
    import_database "Importing data to the MySQL database"
)


add_lemmas_without_boundaries () {
    run_cmd $vrt_fix_attrs --input-fields "word $initial_input_attrs" \
	--output-fields "word $(echo "$initial_input_attrs" | sed -e 's/lemma/lemma:noboundaries lemma/')" \
	--compound-boundary-marker='|' --compound-boundary-can-replace-hyphen
}

add_lemgrams () {
    run_cmd $vrt_add_lemgrams --pos-map-file "$lemgram_posmap" \
	--lemma-field=3 --pos-field=5
}

check_corpus_size () {
    curr_size=$(
	$cwb_describe_corpus $corpus |
	grep -E '^size \(tokens\)' |
	awk '{print $NF}'
    )
    new_size=$(grep -E -cv '^<' $vrt_file)
    if [ $curr_size != $new_size ]; then
	error "The input has $new_size tokens, whereas the existing corpus has $curr_size; aborting"
    fi
}

filter_attrs () {
    _grep_opts="$1"
    shift
    echo "$@" |
    tr ' ' '\n' |
    grep -En $_grep_opts |
    grep -E ":($(echo $new_attrs | sed -e 's/ /|/g'))/?\$"
}

add_new_attrs () {
    # Skip empty lines in the input VRT, in order to avoid a differing
    # number of tokens from the already encoded attributes (assuming
    # that cwb-encode was told to skip empty lines).
    comprcat "${input_files[@]}" |
    grep -v '^$' |
    add_lemmas_without_boundaries |
    add_lemgrams > $vrt_file
    if [ $? != 0 ]; then
	exit_on_error false
    fi
}

test_skip_add_new_attrs () {
    if { corpus_exists $corpus &&
	    corpus_has_attr $corpus p lemmacomp &&
	    corpus_has_attr $corpus p lex; } ||
	{ word_in lemmacomp "$initial_input_attrs" &&
	    word_in lex/ "$initial_input_attrs"; }
    then
	if [ -r $vrt_file.gz ] && [ -s $vrt_file.gz ]; then
	    gunzip $vrt_file.gz
	fi
	if [ ! -r $vrt_file ] || [ ! -s $vrt_file ]; then
	    comprcat "${input_files[@]}" > $vrt_file
	fi
	if [ ! -r $vrt_file ]; then
	    error "Cannot read VRT file $vrt_file"
	elif [ ! -s $vrt_file ]; then
	    error "VRT file $vrt_file is empty"
	fi
	echo "already present"
    fi
}

add_datefromto () {
    local opts
    if [ "x$corpus_date" = "xunknown" ]; then
	opts=--unknown
    elif [ "x$corpus_date" != "x" ]; then
	opts=--fixed=$corpus_date
    fi
    if [ "x$corpus_date_ranges" != "x" ]; then
	opts="$opts --ranges"
    fi
    if [ "x$corpus_date_full_order" != "x" ]; then
	opts="$opts --full-dates --full-date-order=$corpus_date_full_order"
    fi
    run_cmd $vrt_extract_timespans --mode=add --output-full-dates=always \
	$opts "$corpus_date_pattern" < $vrt_file > $vrt_file.new
    mv $vrt_file $vrt_file.old
    mv $vrt_file.new $vrt_file
    rm $vrt_file.old
}

test_skip_add_datefromto () {
    grep -q -s '^<text.* datefrom="' $vrt_file && echo "already present"
}

cwb_encode () {
    local featset_attrnums convert_chars_opts structnames
    featset_attrnums=$(
	printf "word\n"${input_attrs// /\\n} |
	grep -n '/$' |
	cut -d: -f1 |
	tr '\n' ',' |
	sed -e 's/,$//'
    )
    convert_chars_opts=
    if [ "x$featset_attrnums" != "x" ]; then
	convert_chars_opts="--feature-set-attrs $featset_attrnums"
    fi
    echo_verb "  Inferring structural attributes from the VRT file"
    structnames=$(grep '^<' $vrt_file | run_cmd $vrt_list_struct_attrs)
    mkdir_perms $datadir
    run_cmd $vrt_convert_chars $convert_chars_opts < $vrt_file |
    run_cmd $cwb_encode -d $datadir -R $cwb_regdir/$corpus \
	-xsB -c utf8 $(add_prefix "-P " $input_attrs) \
	$(add_prefix "-S " $structnames)
}

test_skip_cwb_encode () {
    [ "x$new_attrs" = x ] && echo "already present"
}

cwb_make () {
    run_cmd $cwb_make -r $cwb_regdir -g $filegroup -p 664 -M 2000 $corpus
}

test_skip_cwb_make () {
    test_skip_cwb_encode
}

convert_timedata () {
    run_cmd $korp_convert_timedata --tsv-dir "$tsvdir" $verbose_opt $corpus
}

test_skip_convert_timedata () {
    corpus_has_attr $corpus s text_timefrom &&
    [ -s $tsvdir/${corpus}_timedata.tsv.gz ] &&
    echo "already converted"
}

extract_info () {
    # --verbose would add the corpus id to the .info file which is not
    # desired.
    run_cmd $cwbdata_extract_info --tsv-dir "$tsvdir" $corpus > $datadir/.info
}

extract_lemgrams () {
    run_cmd $vrt_extract_lemgrams --corpus-id $corpus < $vrt_file |
    gzip > $tsvdir/${corpus}_lemgrams.tsv.gz
}

test_skip_extract_lemgrams () {
    [ -s $tsvdir/${corpus}_lemgrams.tsv.gz ] && echo "already extracted"
}

extract_wordpict_rels () {
    run_cmd $run_extract_rels --corpus-name $corpus \
	--input-fields "word ${input_attrs%/}" \
	--output-dir "$tsvdir" --relation-map "$wordpict_relmap" \
	--optimize-memory --no-tar \
	< $vrt_file
}

test_skip_extract_wordpict_rels () {
    if [ "x$wordpicture" = x ]; then
	echo "requested not to extract"
    elif [ -s $tsvdir/${corpus}_rels.tsv.gz ]; then
	echo "already extracted"
    fi
}

add_name_attrs () {
    run_cmd $vrt_add_name_attrs $corpus @data @data
}

test_skip_add_name_attrs () {
    if [ "x$name_attrs" = x ]; then
	echo "requested not to add"
    elif corpus_has_attr $corpus s ne_ex; then
	echo "already present"
    fi
}

make_corpus_package () {
    local extra_opts
    [ "x$korp_frontend_dir" != x ] &&
    extra_opts="$extra_opts --korp-frontend-dir=$korp_frontend_dir"
    [ "x$package_readme_file" != x ] &&
    extra_opts="--readme-file=$package_readme_file"
    [ "x$package_doc_dir" != x ] &&
    extra_opts="$extra_opts --doc-dir=$package_doc_dir"
    [ "x$package_doc_file" != x ] &&
    extra_opts="$extra_opts --doc-file=$package_doc_file"
    [ "x$package_script_dir" != x ] &&
    extra_opts="$extra_opts --script-dir=$package_script_dir"
    [ "x$package_script_file" != x ] &&
    extra_opts="$extra_opts --script-file=$package_script_file"
    [ "x$package_extra_dir" != x ] &&
    extra_opts="$extra_opts --extra-dir=$package_extra_dir"
    [ "x$package_extra_file" != x ] &&
    extra_opts="$extra_opts --extra-file=$package_extra_file"
    run_cmd gzip --no-name $vrt_file
    run_cmd $korp_make_corpus_package --target-corpus-root /v/corpora \
	--tsv-dir "$tsvdir" --database-format tsv --compress gzip \
	--vrt-file $vrt_file.gz $extra_opts $corpus
}

import_database () {
    tsv_files="$(add_prefix $tsvdir/${corpus}_ lemgrams.tsv.gz timedata.tsv.gz timedata_date.tsv.gz)"
    if [ "x$wordpicture" != x ]; then
	tsv_files="$tsv_files $(echo $tsvdir/${corpus}_rels*.tsv.gz)"
    fi
    run_cmd $korp_mysql_import --prepare-tables --relations-format new \
	$tsv_files
}

test_skip_import_database () {
    [ "x$import_database" = x ] &&
    echo "not requested"
}


main () {
    echo_verb "Making Korp corpus $corpus:"
    # $top_stdout is used by run_cmd to output the command to the top
    # stdout even if the command is run in a pipeline.
    top_stdout=3
    exec 3> /dev/stdout
    set -o pipefail
    run_stages
    exec 3>&-
    ensure_perms $tsvdir/* $vrtdir/* $datadir/* $cwb_regdir/$corpus 2> /dev/null
    echo_verb "Completed."
}


echo_verb $(date +'[%F %T]')
# FIXME: The format is not effective, since the formats used in inner
# time_cmd calls take overwrite the format (TIMEFORMAT environment
# variable).
time_cmd --format "- Total CPU time used: %U %R" main "$@"
echo_verb $(date +'[%F %T]')
