#! /bin/bash
# -*- coding: utf-8 -*-


# TODO:
# - Allow specifying input via options (config file).
# - Allow multiple instances of extra file options to pass to
#   korp-make-corpus-package
# - --add-structure-ids: Specify by structure type if existing values
#   should be overwritten or not.
# - Allow specifying structure id value format.
# - Generate a VRT file containing all the added information: in
#   particular, add the name attributes to the VRT before
#   cwb-encoding.
# - Support different (or multiple) lemma attributes for generating
#   lemmas without compound boundaries, lemgrams and word picture
#   data.
# - Run stages based on checksums of previous stage's output.
# - Make multiple (related) corpora in the same package.
# - Make parallel corpora.
# - (?) Omit positional attributes with a full stop in their names.


progname=`basename $0`
progdir=`dirname $0`

mapdir=$progdir/../corp

vrttoolsdir=$progdir/../vrt-tools

vrt_subdir=vrt/CORPUS
tsv_subdir=$vrt_subdir

lemgram_posmap_default=$mapdir/lemgram_posmap_tdt.tsv
lemgram_posmap_ud_default=$mapdir/lemgram_posmap_ud2_universal.tsv
wordpict_relmap_default=$mapdir/wordpict_relmap_tdt.tsv
wordpict_relmap_ud_default=$mapdir/wordpict_relmap_ud_fi.tsv
compound_boundary_marker_default="|"
compound_boundary_marker_ud_default="#"

usage_header="Usage: $progname [options] [corpus] [input_file ...]

Process a VRT file to make a Korp corpus package containing CWB data files and
MySQL database import files.

The corpus id must be specified either as the first non-option argument or via
the option --corpus-id.

The input files may be either (possibly compressed) VRT files containing
dependency parse information and name tags, or ZIP or (possibly compressed)
tar archives containing such VRT files. If no input files are specified, read
from the standard input or use a VRT file stored on a previous run for the
same corpus.

If rerun on a corpus and processed data for the corpus exists, try to infer
which processing stages needs to be rerun. However, run all processing stages
if --force is specified or if any of the input files is newer than the VRT
file stored on a previous run."

optspecs='
@ General options

corpus-id=CORPUS corpus
    make corpus with id CORPUS; this is alternative to specifying the
    corpus id as the first non-option argument
force
    force all stages of processing by first removing all the output
    files if they exist; existing output files are also removed if any
    of the input files is newer than the VRT file stored on a previous
    run for the same corpus (unless --augment-data is specified)
config-file|configuration-file=FILE
    read FILE as an INI-style configuration file (without sections).
    Configuration keys correspond to option names without the leading
    dashes; internal dashes may be replaced with underscores.

@ Diagnostic output

v|verbose "1"
    output some progress information (the default)
quiet { verbose= }
    do not output progress information (except for some subprocesses)
times show_times
    output the amount of CPU time used for each stage
log-file=FILE logfile
    log script output (standard output and standard error) to FILE
    instead of the default
    $corpus_root/log/${progname}_CORPUS_TIMESTAMP.log where CORPUS is
    the corpus id and TIMESTAMP the start time of the script
no-logging !logging
    do not copy script output to a log file

@ Directories

c|corpus-root=DIR "$corpus_root" { set_corpus_root "$1" }
    use DIR as the root directory of corpus files
tsv-dir=DIR "CORPUS_ROOT/$tsv_subdir" tsvdir
    output database tables as TSV files to DIR

@ Corpus licence information

licence-type=LIC auth_opts { add_auth_opts licence_type $optname $1 }
    set the corpus licence type to LIC, where LIC is one of PUB, ACA,
    ACA-Fi or RES
lbr-id=URN { add_auth_opts lbr_id $optname $1 }
    set the LBR id of the corpus to URN, which is of the form
    [urn:nbn:fi:lb-]YYYYMMNNN[@LBR], where YYYYMM is year and month
    and NNN 3 to 5 digits; the bracketed parts are added if left out

@ Input attributes

input-attrs|input-attributes|input-fields=ATTRS \
  "word ref lemma pos msd dephead deprel nertag" initial_input_attrs
    specify the names of the positional attributes in the input,
    separated by spaces; if "word" (token) is not included in the
    list, add it as the first attribute, unless --no-word-attribute is
    specified;
    if the input VRT contains a positional attributes comment, it
    overrides this option, unless --override-vrt-attributes is
    specified;
    attributes named "_" or with names beginning with a "-" are
    skipped in the input;
    if ATTRS contains attribute names suffixed with "_ud", "_ud1" or
    "_ud2" and no corresponding attributes without the suffix, the
    suffix is stripped
override-vrt-attrs|override-vrt-attributes
    use the positional attributes specified with --input-attributes
    even if the input VRT contains a positional attributes comment
omit-attributes|skip-attributes=ATTRS omit_attrs
    omit the positional input attributes listed in ATTRS (seprated by
    spaces)
no-word-attribute no_word_attr
    the input does not contain a "word" attribute; implied by
    --augment-data
keep-attr-order|keep-attribute-order
    do not reorder positional attributes even if "word" is not the
    first attribute; implied by --augment-data
augment-data|augment-existing-data
    augment existing corpus data with the data in the input, for
    example, to add parse annotations to a corpus already encoded; if
    the input contains values for existing attributes, they override
    existing values; you cannot use this option with --force
generate-input-from-data generate_input
    use the existing (CWB) corpus data as the input, which is to be
    augmented if needed with lemgrams, lemmas without compound
    boundaries and the appropriate database data (implies
    --augment-data); the list of input attribute names is read from
    the data (overrides --input-attrs); you cannot use this option
    with --force

@ Annotation mappings

lemgram-posmap|posmap=POSMAP_FILE "'"$lemgram_posmap_default"'"
    use POSMAP_FILE as the mapping file from the corpus parts of
    speech to those used in Korp lemgrams; the file should contain
    lines with corpus POS and lemgram POS separated by a tab;
    if the positional attributes contain UD annotations and no non-UD
    annotations, file "'"$lemgram_posmap_ud_default"'" is used unless
    a different file is specified explicitly
wordpict-relmap|wordpicture-relation-map=RELMAP_FILE \
  "'"$wordpict_relmap_default"'"
    use RELMAP_FILE as the mapping file from corpus dependency
    relation codes to those used in the Korp word picture; the file
    should contain lines with corpus dependency relation code and word
    picture dependency relation code separated by a tab;
    if the positional attributes contain UD annotations and no non-UD
    annotations, file "'"$wordpict_relmap_ud_default"'" is used unless
    a different file is specified explicitly

@ Compound boundaries

compound-boundary-marker=MARKER "'"$compound_boundary_marker_default"'"
    the string MARKER marks compound boundaries in lemmas and will be
    removed from lemmas without compound boundaries;
    if the positional attributes contain UD annotations and no non-UD
    annotations, "'"$compound_boundary_marker_ud_default"'" is used
remove-compound-boundary-algorithm=ALGORITHM "omorfi" compound_boundary_alg
    use ALGORITHM for adding lemmas without compound boundaries, one
    of "omorfi", "old" (alias "simple-omorfi") and "naive": "omorfi"
    handles some idiosyncrasies of Omorfi, "old" produces results
    (mostly) compatible with the algorithm used previously (handling
    hyphens replaced with compound boundary markers), and "naive"
    simply removes compound boundary markers

@ Lemgrams

add-lowercase-lemgrams { add_lemgram_opt --add-lowercase-variants }
    add all-lower-case variants of lemgrams for lemmas containing
    upper-case letters
add-lemgrams-without-diacritics { add_lemgram_opt --add-non-diacritic-variants }
    add variants of lemgrams without diacritics for lemmas containing
    letters with diacritics
lemgrams-keep-letters-with-diacritics=CHARS \
  { add_lemgram_opt --keep-letters-with-diacritics "$1" }
    Keep the letters with diacritics in CHARS intact even in lemgram
    variants otherwise without diacritics. CHARS is a string of
    characters that can be used inside a set of characters in a
    regular expression (as [^CHARS]). CHARS are retained regardless of
    their case.

@ Structure ids

add-structure-ids|add-element-ids=STRUCTLIST \
  "text paragraph sentence" add_struct_ids
    add id attributes to the structures listed in STRUCTLIST
    (separated by spaces); if STRUCTLIST is an empty string, do not
    add id attributes
overwrite-structure-ids|overwrite-element-ids !keep_struct_ids
    overwrite possible existing id attribute values in the structures
    listed with --add-structure-ids

@ Sorting text structures

text-sort-attribute=ATTRLIST * { add_text_sort_opt --key "$1" }
    Sort text elements in the corpus by the attributes listed in
    ATTRLIST, separated by spaces or commas. Sort primarily by the
    first attribute, secondarily by the second and so on, by byte
    values, without taking the locale into account. Multiple keys can
    also be specified by repeating the option. Each attribute name may
    be followed by a colon and sort ordering option characters
    recognized by the "sort" command: often one or more of the
    following: b (ignore leading blanks), d (dictionary order), f
    (ignore case), g (general numeric sort), i (ignore nonprinting), M
    (month sort), h (human numeric sort), R (random sort), r
    (reverse), V (version sort).
text-sort-transform=ATTR:TRANSFORM '"'"' * { add_text_sort_opt --transform "$1" }
    Transform the value of the attribute attrname using TRANSFORM
    before using it as a sort key. ATTR is one of the attributes
    listed in the argument of --text-sort-attribute. (ATTR and the
    colon may be omitted if only one key attribute is specified.)
    TRANSFORM may be one of the following: (1) a Perl-style
    substitution "s/regexp/subst/[flags]", where regexp and subst
    follow Python regular expression syntax and flags is zero or more
    of the following letters: a (make \\w, \\W, \\b, \\B, \\d, \\D
    match ASCII characters only instead of whole Unicode), g (replace
    all matches and not only the first one), i (match
    case-insensitively), l (make \\w, \\W, \\b, \\B dependent on the
    current locale), x (ignore whitespace and comments); (2) a single
    Python expression; or (3) the body of a Python function. In (2)
    and (3), the variable "val" refers to the value of the attribute
    (str), and they return the result of the transformation (converted
    to str). If (3) has no return statement, the value of "val" is
    returned. On an error depending on the value of "val", an empty
    string is returned. The option may be repeated to specify
    transformations for different attributes and/or multiple
    transformations for a single attribute. Multiple transformations
    for an attribute are processed in the order they are specified.

@ Omitting structures

omit-structures=STRUCTS
    omit structures listed in STRUCTS, separated by spaces; you cannot
    omit text or sentence structures; this can be used to remove
    paragraphs from corpora whose sentences should be scrambled within
    whole texts

@ Scrambling structures

scramble=STRUCTS
    scramble structures listed in STRUCTS, separated by spaces;
    typical structures are sentence and paragraph (and link for
    parallel corpus parts); they are scrambled within the immediately
    containing structure, typically within paragraph and text,
    respectively; "sentence paragraph" scrambles both ways
scramble-seed=SEED
    use the string SEED as the random number generator seed for
    scrambling data; "0" for random seed (non-reproducible order)
    (default: corpus id)

@ Copying and renaming structural attributes

copy-struct-attr|copy-structure-attribute=TARGET:SOURCELIST *
    copy structural attributes from a preceding (enclosing) structure.
    TARGET is the name of the structure to which attributes are to be
    copied and SOURCELIST is a semicolon-separated list of items of
    the form SOURCESTRUCT/ATTRLIST, where SOURCESTRUCT is the source
    structure and ATTRLIST is a comma-separated list of the names of
    attributes in SOURCESTRUCT to be copied, or "*" for all
    attributes. For example, the value
    "sentence:paragraph/type,speaker" specifies that the values of the
    attributes type and speaker of the preceding (enclosing) paragraph
    structure are added to the attributes of a sentence structure,
    named paragraph_type and paragraph_speaker. Copying attributes
    takes place before omitting structures, so for example, paragraph
    attributes may be copied to sentences before removing paragraphs.
    Multiple attribute copy operations may be specified either by
    listing them in the argument separated by spaces or by specifying
    this option multiple times.
rename-struct-attr|rename-structure-attribute=STRUCT/SOURCE:TARGET *
    rename in structure STRUCT attributes matching the (Perl) regular
    expression SOURCE as TARGET. SOURCE needs to be mathced in full.
    SOURCE may contain capture groups (...) and TARGET may reference
    them as \$1, \$2 and so on. Attributes are renamed after copying
    (see above), so you can rename copied attributes. Multiple
    attribute rename operations may be specified either by listing
    them in the argument separated by spaces or by specifying this
    option multiple times.

@ Date information

corpus-date=DATE
    use DATE as the date of all texts in the corpus; "unknown" if not
    known
corpus-date-pattern=PATTERN
    recognize corpus date information based on PATTERN of the form
    "ELEM ATTR REGEX": extract date information from the attribute
    ATTR of element (structural attribute) ELEM using the regular
    expression REGEX. ELEM and ATTR may be "*" (any element or
    attribute) or they may contain several attribute or element names
    separated with vertical bars. REGEX may contain named groups
    (subpatterns) in Python'"'"'s regular expressions Y, M and D,
    which extract year, month and day; for example, "(?P<Y>[0-9]{4})"
    (without the quotation marks) would recognize a year (although
    this particular case is also covered by the default pattern).
    REGEX may also cover both the start and end date, in which case
    the subpatterns for the start date are Y1, M1 and D1, and those
    for the end date, Y2, M2 and D2. If REGEX does not contain named
    subpatterns, recognize the first group as the start date and the
    possible second group as the end date.
corpus-date-full-order=ORDER
    recognize full dates in the order ORDER (one of "ymd", "dmy",
    "mdy")
corpus-date-ranges
    make the patterns recognize date ranges with different start and
    end days

@ Output data

no-lemmas-without-boundaries|skip-lemmas-without-boundaries \
  !lemmas_without_boundaries
    do not add lemmas without compound boundaries
no-lemgrams|skip-lemgrams !lemgrams
    do not add lemgrams
no-wordpicture|skip-wordpicture !wordpicture
    do not extract word picture relations database tables
no-name-attrs|no-name-attributes|skip-name-attrs|skip-name-attributes \
  !name_attrs
    do not add named-entity information based on a NER tag as the last
    positional attribute
remake-wordpicture-data
    force remaking word picture relations database tables; this option
    is needed only if recreating word picture data that has been left
    incomplete on a previous run

@ Packaging

no-package !make_package
    do not create a corpus package
korp-frontend-dir=DIR "$korp_frontend_dir"
    read Korp configuration files from DIR, to be included in corpus
    package
package-readme-file|readme-file=FILE
    include FILE as a top-level read-me file in the corpus package;
    FILE may contain shell wildcards (but braces are not expanded)
package-doc-dir|doc-dir=DIR
    include DIR as a documentation directory "doc" in the corpus
    package
package-doc-file|doc-file=FILE
    include FILE as a documentation file in directory "doc" in the
    corpus package; FILE may contain shell wildcards
package-script-dir|script-dir=DIR
    include DIR as a (conversion) script directory "scripts" of
    the corpus package
package-script-file|script-file=FILE
    include FILE as a (conversion) script file in directory "scripts"
    of the corpus package; FILE may contain shell wildcards
package-extra-dir|extra-dir=SRCDIR[:DSTDIR]
    include directory SRCDIR in the corpus package; if :DSTDIR is
    specified, the directory is renamed as DSTDIR in the package
package-extra-file|extra-file=SRCFILE[:DSTFILE]
    include file SRCFILE in the corpus package; if :DSTFILE is
    specified, the file is renamed as DSTFILE in the package; if
    DSTFILE ends in a slash or if SRCFILE contains wildcards, DSTFILE
    is considered a directory name and SRCFILE is placed in that
    directory in the package

@ Database import

import-database
    import the database TSV files into the Korp MySQL database
'

config_file_optname=config-file


. $progdir/korp-lib.sh

# cleanup_on_exit=


vrt_rename_struct_attrs=$progdir/vrt-rename-struct-attrs.pl
vrt_fix_attrs=$progdir/vrt-fix-attrs.py
vrt_add_lemma_nobound=$vrttoolsdir/vrt-add-lemma-nobound
vrt_add_lemgrams=$progdir/vrt-add-lemgrams.py
vrt_sort=$vrttoolsdir/vrt-sort
vrt_add_struct_ids=$progdir/vrt-add-struct-ids.sh
vrt_convert_chars=$progdir/vrt-convert-chars.py
vrt_extract_timespans=$progdir/vrt-extract-timespans.py
vrt_list_struct_attrs=$progdir/vrt-list-struct-attrs.py
korp_convert_timedata=$progdir/korp-convert-timedata.sh
vrt_scramble=$progdir/vrt-scramble.py
cwbdata_extract_info=$progdir/cwbdata-extract-info.sh
vrt_extract_lemgrams=$progdir/vrt-extract-lemgrams.sh
run_extract_rels=$progdir/run-extract-rels.sh
vrt_add_name_attrs=$progdir/vrt-add-name-attrs.sh
korp_make_corpus_package=$progdir/korp-make-corpus-package.sh
korp_mysql_import=$progdir/korp-mysql-import.sh
cwbdata2vrt="$progdir/cwbdata2vrt-simple.sh --all-attributes --output-file=-"

cwb_encode=$cwb_bindir/cwb-encode
cwb_describe_corpus=$cwb_bindir/cwb-describe-corpus
cwb_make=$cwb_perl_bindir/cwb-make

vrt_file=


text_sort_opts=
sort_texts=
add_lemgrams_opts=


add_auth_opts () {
    local type opt val
    type=$1
    opt=$2
    val=$3
    val=$(eval "make_$type \$val")
    exit_if_error $?
    auth_opts="$auth_opts $opt $val"
}

add_text_sort_opt () {
    local optname=$1
    local optarg=$2
    if [ "x$optname" = "x--key" ]; then
	sort_texts=1
    fi
    text_sort_opts="$text_sort_opts $optname $(quote_args_safe "$optarg")"
}

add_lemgram_opt () {
    local optname=$1
    local optarg=$2
    # optarg may not contain spaces, but in this case they should not
    # occur
    add_lemgrams_opts="$lemgram_opts $optname $optarg"
}

# Process options
eval "$optinfo_opt_handler"

if [ "x$corpus" = "x" ]; then
    if [ "x$1" = "x" ]; then
	error "No corpus name specified"
    fi
    corpus=$1
    shift
fi

preprocess_posattrs=
initial_vrt_posattrs=

if [ "x$generate_input" != x ]; then
    if [ "x$force" != x ]; then
	error "You cannot specify both --force and --generate-input-from-data"
    fi
    augment_data=1
    stage1_fn=generate_input
    stage1_descr="Generating input VRT file from CWB data"
else
    stage1_fn=combine_input
    stage1_descr="Combining input files"
fi

if [ "x$augment_data" != x ]; then
    if [ "$(list_corpora --on-error : "$corpus")" != "$corpus" ]; then
	error "Corpus $corpus not found; cannot augment corpus data"
    fi
    if [ "x$force" != x ]; then
	error "You cannot specify both --force and --augment-data"
    fi
fi

if [ "x$logging" != x ]; then
    if [ "x$logfile" = x ]; then
	if [ ! -e "$corpus_root/log" ]; then
	    mkdir_perms $corpus_root/log
	fi
	logfile=$corpus_root/log/${progname}_${corpus}_$(date +'%Y%m%d%H%M%S').log
    fi
    # http://stackoverflow.com/questions/3173131/redirect-copy-of-stdout-to-log-file-from-within-bash-script-itself
    cat < /dev/null > $logfile
    ensure_perms $logfile
    exec > >(tee -ia $logfile)
    exec 2> >(tee -ia $logfile >&2)
    echo_verb "Logging output to $logfile"
fi

if [ "x$omit_structures" != x ]; then
    if word_in "text" "$omit_structures" ||
	    word_in "sentence" "$omit_structures"
    then
	error "You cannot omit text or sentence structures"
    fi
    # Use echo to get single spaces between structures to be omitted
    omit_structures=$(echo $omit_structures)
    # Convert to a regexp for grep -Ev
    omit_structures="^</?(${omit_structures// /|})[ >]"
fi

# Convert to lowercase
compound_boundary_alg=${compound_boundary_alg,,}
case $compound_boundary_alg in
    old )
	compound_boundary_alg=simple-omorfi
	;;
    omorfi | naive | simple-omorfi )
	# Use the value as is
	:
	;;
    * )
	error 'Invalid algorithm in --remove-compound-boundary-algorithm: allowed values are "omorfi", "legacy" and "naive".'
	;;
esac

echo_verb "Running: $cmdline_orig"
echo_verb "Processed arguments: $cmdline_args_processed"

input_files=( "$@" )

vrtdir=${vrtdir:-$corpus_root/$vrt_subdir}
vrtdir=${vrtdir//CORPUS/$corpus}
tsvdir=${tsvdir:-$corpus_root/$tsv_subdir}
tsvdir=${tsvdir/CORPUS_ROOT/$corpus_root}
tsvdir=${tsvdir//CORPUS/$corpus}
datadir=$corpus_root/data/$corpus

mkdir_perms $vrtdir $tsvdir 2> /dev/null

if [ "x$vrt_file" = "x" ]; then
    # If augmenting data and not generating input from VRT, do not use
    # possible existing VRT file. Another option might be to have an
    # option for ignoring an existing VRT file and to write the
    # augmented VRT file to $corpus.augm.vrt, for example.
    if [ "x$augment_data" != x ] && [ "x$generate_input" = x ]; then
	vrt_file=$tmp_prefix.$corpus.vrt
    else
	vrt_file=$vrtdir/$corpus.vrt
    fi
fi

verbose_opt=
if [ "x$verbose" != x ]; then
    verbose_opt=--verbose
fi


remove_existing_data () {
    rm -f $datadir/* $cwb_regdir/$corpus $tsvdir/$corpus_*.tsv.gz \
       $vrtdir/$corpus.vrt $vrtdir/$corpus.vrt.gz
}

run_cmd () {
    verbose printf "  Running: " >&$top_stdout
    verbose echo_quoted "$@" >&$top_stdout
    "$@"
}

process_vrt () {
    run_cmd "$@" < $vrt_file > $vrt_file.new
    replace_file $vrt_file $vrt_file.new
}

time_stage () {
    time_cmd --format "- CPU time used: %U %R" "$@"
}

check_errors_from_log () {
    # FIXME: Grepping the log file for system error messages is a bit
    # kludgy way to catch "Disk quota exceeded" (and possibly other
    # similar) system errors. In particular, the error might prevent
    # the process from writing the message to the log file. The
    # subprocesses should notice the errors and exit with an error
    # status. Or can they do that?
    if grep '^\[Errno [0-9]' "$logfile" \
	> $tmp_prefix.subproc_error 2> /dev/null;
    then
	error "Aborting because of an error: $(cat $tmp_prefix.subproc_error)"
    fi
}

# Run a single stage function (name) after printing the description
# (descr). If function test_skip_$name is defined and its output is
# non-empty, skip the stage.
run_stage () {
    local name=$1
    if [ "x$name" = x ]; then
	return
    fi
    shift
    local descr="$@"
    local msg exitstat
    if type -t "test_skip_$name" > /dev/null; then
	msg=$(test_skip_$name 2> $tmp_prefix.errmsg)
	exitstat=$?
	# Exit with error if the test function (or the programs it
	# runs) outputs something to stderr. An alternative would be [
	# $? != 0 ], but that would require adding "return 0" to many
	# of the test_skip_ functions.
	if [ -s $tmp_prefix.errmsg ]; then
	    cat $tmp_prefix.errmsg
	    exit $exitstat
	fi
	if [ "x$msg" != "x" ]; then
	    echo_verb "(Skipping ${descr,}: $msg)"
	    return
	fi
    fi
    echo_verb "$descr"
    time_stage exit_on_error $name
    check_errors_from_log
}

# Run all the stages in $stages sequentially.
run_stages () {
    local stagecnt=${#stages[*]}
    local i=0
    while [ $i -lt $stagecnt ]; do
	run_stage ${stages[$i]} "${stages[$(($i + 1))]}"
	i=$(($i + 2))
    done
}


# Stage functions and their descriptions
stages=(
    "$stage1_fn" "$stage1_descr"
    check_input_attrs "Checking input attributes"
    # Stage 3 information set in check_input_attrs if needed
    "" ""
    copy_struct_attrs "Copying structural attributes"
    rename_struct_attrs "Renaming structural attributes"
    omit_structures "Omitting structures"
    add_lemmas_without_boundaries "Adding lemmas without compound boundaries"
    add_lemgrams "Adding lemgrams"
    add_datefromto "Adding datefrom and dateto"
    sort_texts "Sorting text elements"
    scramble_structs "Scrambling structures"
    add_struct_ids "Adding structure ids"
    cwb_encode "Encoding the attributes for CWB"
    cwb_make "Indexing and compressing the CWB data"
    convert_timedata "Converting and augmenting time data"
    extract_info "Extracting information for the .info file"
    extract_lemgrams "Extracting lemgrams for the database"
    extract_wordpict_rels
    "Extracting word picture relations for the database"
    add_name_attrs "Adding name attributes"
    adjust_posattrs_comment "Adjusting or adding VRT positional-attributes comment"
    make_corpus_package "Creating corpus package"
    import_database "Importing data to the MySQL database"
)


combine_input () {
    local input_token_count existing_token_count
    # Skip empty lines in the input VRT, in order to avoid a differing
    # number of tokens from the already encoded attributes (assuming
    # that cwb-encode was told to skip empty lines).
    comprcat "${input_files[@]}" |
    grep -v '^$' > $vrt_file
    input_token_count=$(vrt_get_token_count "$vrt_file")
    if [ "$input_token_count" = 0 ]; then
	error "No tokens in the input"
    fi
    echo_verb "  $input_token_count tokens in the input VRT"
    if [ "x$augment_data" != x ]; then
	existing_token_count=$(get_corpus_token_count $corpus)
	if [ "$input_token_count" != "$existing_token_count" ]; then
	    error "The number of tokens in the input ($input_token_count) differs from that in the existing corpus data ($existing_token_count)"
	fi
    fi
}

test_skip_combine_input () {
    if [ -r $vrt_file.gz ] && [ -s $vrt_file.gz ]; then
	gunzip $vrt_file.gz
    fi
    if [ -r $vrt_file ] && [ -s $vrt_file ]; then
        # If any of specified the input files is newer than the
        # existing VRT file and not augmenting data, remove existing
        # data
        if [ "x$augment_data" = x ] &&
               [ "${#input_files[@]}" -gt 0 ] &&
               ! file_newer $vrt_file "${input_files[@]}";
        then
            remove_existing_data
        else
	    echo "using existing VRT file $vrt_file"
        fi
    fi
}

check_input_attrs () {
    local next_stage_fn=
    local next_stage_descr=
    local next_stage_descr2=
    local next_stage_idx=
    local attrnum_word=
    local attrcount=
    local vrt_attrcount=
    initial_vrt_posattrs=$(vrt_get_posattr_names $vrt_file)
    if [ "x$initial_vrt_posattrs" != x ]; then
	if [ "x$override_vrt_attrs" = x ]; then
	    initial_input_attrs=$initial_vrt_posattrs
	    # The lex attribute in the positional attributes comment
	    # might lack the final slash, but lex (lemgram) is always
	    # a feature-set attribute, so add it if needed.
	    initial_input_attrs=$(suffix_word "$initial_input_attrs" lex /)
	    verbose safe_echo "Using positional attributes named in the input VRT: $initial_input_attrs"
	elif [ "$initial_vrt_posattrs" != "$initial_input_attrs" ] &&
		 [ "$initial_vrt_posattrs" != "word $initial_input_attrs" ];
	then
	    warn "Overriding positional attributes \"$initial_vrt_posattrs\" in the input VRT with \"$initial_input_attrs\""
	fi
    else
	verbose safe_echo "No positional attributes named in the input VRT; using those listed with --input-attributes: $initial_input_attrs"
    fi
    # FIXME: Testing for UD attributes (and setting lemgramp_posmap
    # and wordpict_relmap accordingly) does not work if using an
    # existing VRT file with the attributes already renamed, for
    # example, if later adding lemgram or word picture data
    if has_only_ud_attrs $initial_input_attrs; then
        initial_input_attrs=$(rename_ud_attrs $initial_input_attrs)
        verbose safe_echo "Removing suffix _ud[12]? from positional attribute names, as no corresponding attributes without the suffix; modified input attributes: $initial_input_attrs"
        if word_in "pos" "$initial_input_attrs" &&
                [ "$lemgram_posmap" = "$lemgram_posmap_default" ]
        then
            lemgram_posmap=$lemgram_posmap_ud_default
            verbose safe_echo "Using the default UD lemgram part-of-speech mapping file $lemgram_posmap_ud_default"
        fi
        if word_in "deprel" "$initial_input_attrs" &&
                [ "$wordpict_relmap" = "$wordpict_relmap_default" ]
        then
            wordpict_relmap=$wordpict_relmap_ud_default
            verbose safe_echo "Using the default UD word picture relation mapping file $wordpict_relmap_ud_default"
        fi
        if [ "x$lemmas_without_boundaries" != x ] &&
               word_in "lemma" "$initial_input_attrs"
        then
            compound_boundary_marker=$compound_boundary_marker_ud_default
            verbose safe_echo "Using the default UD compound boundary marker \"$compound_boundary_marker_ud_default\""
        fi
    fi
    if [ "x$augment_data" != x ]; then
	keep_attr_order=1
	no_word_attr=1
    fi
    attrnum_word="$(word_index word $initial_input_attrs)"
    if [ "x$no_word_attr" = x ] && [ "$attrnum_word" = "-1" ]; then
	initial_input_attrs="word $initial_input_attrs"
    fi
    attrcount=$(count_words $initial_input_attrs)
    vrt_attrcount=$(vrt_get_posattr_count $vrt_file)
    if [ "$attrcount" != "$vrt_attrcount" ]; then
	error "Error: the input VRT has $vrt_attrcount positional attributes, but $attrcount were specified"
    fi
    if word_in _ "$initial_input_attrs" ||
	    [ "${initial_input_attrs#*-}" != "$initial_input_attrs" ] ||
            [ "x$omit_attrs" != x ]
    then
	next_stage_fn=filter_and_reorder_posattrs
	next_stage_descr="Filtering out positional attributes with name \"_\" or starting with \"-\" or specified with --omit-attributes"
	preprocess_posattrs=filter
    fi
    if [ "x$keep_attr_order" = x ] &&
	   [ "$attrnum_word" != "-1" ] && [ "$attrnum_word" != "1" ]
    then
	next_stage_fn=filter_and_reorder_posattrs
	next_stage_descr2='moving "word" to be the first positional attribute'
	if [ "x$next_stage_descr" != x ]; then
	    next_stage_descr="$next_stage_descr, and $next_stage_descr2"
	else
	    next_stage_descr=${next_stage_descr2^}
	fi
	preprocess_posattrs="$preprocess_posattrs reorder"
    fi
    # filter_and_reorder_posattrs adds a positional attributes comment
    # if it is missing, so if it will be run, do not do it here.
    if [ "x$next_stage_fn" = x ] && [ "x$initial_vrt_posattrs" = x ]; then
	process_vrt vrt_replace_posattr_names "$initial_input_attrs"
	initial_vrt_posattrs=$initial_input_attrs
    fi
    next_stage_idx=$(first_empty_elem_index "${stages[@]}")
    stages[$next_stage_idx]=$next_stage_fn
    stages[$(($next_stage_idx + 1))]=$next_stage_descr
    input_attrs=$initial_input_attrs
}

has_only_ud_attrs () {
    # Check if the arguments has attribute names with suffix _ud, _ud1
    # or _ud2 without corresponding non-suffixed attributes
    # TODO: Also return false if multiple different _ud attributes,
    # e.g. _ud1, _ud2
    local attrs attr attr_base has_ud
    has_ud=1
    attrs="$@"
    for attr in $attrs; do
        if str_hassuffix "$attr" "_ud[12]" || str_hassuffix "$attr" "_ud"; then
            has_ud=0
            attr_base=${attr%_ud*}
            if word_in "$attr_base" "$attrs"; then
                return 1
            fi
        fi
    done
    return $has_ud
}

rename_ud_attrs () {
    # Remove suffix _ud, _ud1 or _ud2 from attribute names given as
    # arguments
    local attrs=
    local attr
    for attr in "$@"; do
        attr=${attr%_ud[12]}
        attr=${attr%_ud}
        if [ "x$attrs" = x ]; then
            attrs=$attr
        else
            attrs="$attrs $attr"
        fi
    done
    echo "$attrs"
}

first_empty_elem_index () {
    # Return the index of the first empty element in the argument array
    local arr=("$@")
    local i
    i=0
    while [ $i -lt ${#arr[@]} ]; do
        if [ "${arr[$i]}" = "" ]; then
            echo $i
            return
        fi
        i=$(($i + 1))
    done
}

filter_and_reorder_posattrs () {
    local attrs_names=
    local attrs_nums=
    local word_filter=true
    local skip_attrs=
    # set -vx
    if word_in reorder "$preprocess_posattrs"; then
	attrs_names=word
	attrs_nums="\$$(word_index word $initial_input_attrs)"
	word_filter='[ "$attrname" != "word" ]'
    fi
    local attrname
    local attrnum=1
    for attrname in $initial_input_attrs; do
	if [ "$attrname" != "_" ] &&
	       [ "${attrname#-}" = "$attrname" ] &&
               ! word_in "$attrname" "$omit_attrs" &&
	       eval "$word_filter"
	then
	    attrs_names="$attrs_names $attrname"
	    attrs_nums="$attrs_nums, \$$attrnum"
        elif [ "$attrname" != "word" ]; then
            skip_attrs="$skip_attrs $attrname"
	fi
	attrnum=$(($attrnum + 1))
    done
    attrs_names=${attrs_names# }
    attrs_nums=${attrs_nums#,}
    if [ "x$skip_attrs" != x ]; then
        echo_verb "  Filtering out positional attributes:$skip_attrs"
    fi
    # set +vx
    process_vrt awk -F"$tab" '
		BEGIN {
		    OFS = "\t"
	        }
		/^</ { print }
		/^[^<]/ { print '"$attrs_nums"' }'
    initial_input_attrs=$attrs_names
    input_attrs=$attrs_names
    if [ "$initial_vrt_posattrs" != "$attrs_names" ]; then
        initial_vrt_posattrs=$attrs_names
        adjust_posattrs_comment
    fi
}

generate_input () {
    # TODO: Set initial_vrt_posattrs here too
    existing_token_count=$(get_corpus_token_count $corpus)
    echo_verb "  $existing_token_count tokens in the existing data"
    run_cmd $cwbdata2vrt $corpus > $vrt_file
    # Use echo to convert newlines in corpus_list_attrs to spaces
    input_attrs=$(echo $(corpus_list_attrs $corpus POS))
    # Replace lex with lex/ (lemgram has feature-set values)
    input_attrs=$(suffix_word "$input_attrs" lex /)
    initial_input_attrs=$input_attrs
}

copy_struct_attrs () {
    process_vrt $vrt_fix_attrs \
		$(add_prefix "--copy-struct-attribute " $copy_struct_attr)
}

test_skip_copy_struct_attrs () {
    [ "x$copy_struct_attr" = x ] &&
	echo "not requested"
}

rename_struct_attrs () {
    process_vrt $vrt_rename_struct_attrs $rename_struct_attr
}

test_skip_rename_struct_attrs () {
    [ "x$rename_struct_attr" = x ] &&
	echo "not requested"
}

omit_structures () {
    process_vrt grep -Ev "$omit_structures"
}

test_skip_omit_structures () {
    [ "x$omit_structures" = x ] &&
	echo "not requested"
}

add_lemmas_without_boundaries () {
    # TODO: Recognize lemma attributes suffixed with annotation scheme
    # (lemma_ud1) and add the corresponding lemmas without compound
    # boundaries
    process_vrt $vrt_add_lemma_nobound \
		--mode=$compound_boundary_alg \
		--compound-boundary-marker="$compound_boundary_marker" \
		--add-name=lemmacomp --add-type=boundaries \
		--add-after-name=lemma
    input_attrs=$(suffix_word "$input_attrs" lemma " lemmacomp")
}

test_skip_add_lemmas_without_boundaries () {
    if [ "x$lemmas_without_boundaries" = x ]; then
	echo "requested not to add"
    elif ! word_in lemma "$initial_input_attrs"; then
	echo "no attribute lemma"
    elif { corpus_exists $corpus &&
	    corpus_has_attr $corpus p lemmacomp; } ||
	word_in lemmacomp "$initial_input_attrs"
    then
	echo "already present"
    fi
}

add_lemgrams () {
    process_vrt $vrt_add_lemgrams --pos-map-file "$lemgram_posmap" \
	--lemma-field=$(get_attr_num lemma "$input_attrs") \
	--pos-field=$(get_attr_num pos "$input_attrs") \
        $add_lemgrams_opts
    if [ $? != 0 ]; then
	exit_on_error false
    fi
    input_attrs="$input_attrs lex/"
    # This is some extra work but is needed to keep the
    # positional-attributes comment in sync with the content as long
    # as vrt-add-lemgrams does not handle the comment
    adjust_posattrs_comment
}

test_skip_add_lemgrams () {
    local attr
    if [ "x$lemgrams" = x ]; then
	echo "requested not to add"
    elif { corpus_exists $corpus &&
	    corpus_has_attr $corpus p lex; } ||
	word_in lex/ "$initial_input_attrs"
    then
	echo "already present"
    else
	for attr in lemma pos; do
	    if ! { word_in $attr "$initial_input_attrs" ||
		    word_in $attr/ "$initial_input_attrs"; }
	    then
		echo "no attribute $attr"
		break
	    fi
	done
    fi
}

add_datefromto () {
    local opts
    if [ "x$corpus_date" = "xunknown" ]; then
	opts=--unknown
    elif [ "x$corpus_date" != "x" ]; then
	opts=--fixed=$corpus_date
    fi
    if [ "x$corpus_date_ranges" != "x" ]; then
	opts="$opts --ranges"
    fi
    if [ "x$corpus_date_full_order" != "x" ]; then
	opts="$opts --full-dates --full-date-order=$corpus_date_full_order"
    fi
    if [ "x$corpus_date_pattern" != x ]; then
	opts="$opts --pattern $(quote_args_safe "$corpus_date_pattern")"
    fi
    # Use eval to get the quoted argument of --pattern correctly
    eval process_vrt $vrt_extract_timespans --mode=add \
	--output-full-dates=always $opts
}

test_skip_add_datefromto () {
    if ! grep -q -s '^<text ' $vrt_file; then
        echo "no text structures"
    elif grep -q -s '^<text.* datefrom="' $vrt_file; then
        echo "already present"
    fi
}

sort_texts () {
    # Use eval to get the separate options in $text_sort_opts
    # correctly
    eval process_vrt $vrt_sort $text_sort_opts
}

test_skip_sort_texts () {
    [ "x$sort_texts" = x ] &&
    echo "not requested"
}

# find_containing_struct struct vrt_fname
#
# Print the structure immediately containing struct in the VRT file
# vrt_fname, an empty string if struct is the top-level structure. If
# struct is not found in vrt_fname, return error.
#
# This assumes that if the text has paragraphs, no sentence is outside
# a paragraph. Likewise, if the text has chapters between text and
# paragraph, all paragraphs should be inside a chapter. This also does
# not work with crossing structures, like lines or pages interleaved
# with others. It is unclear how or if scrambling should be done in
# such cases.
find_containing_struct () {
    local struct vrt_fname exitcode
    struct=$1
    vrt_fname=$2
    grep -q -s "^<$struct" $vrt_fname
    exitcode=$?
    if [ $exitcode != 0 ]; then
	return $exitcode
    fi
    grep '^<' $vrt_fname |
    awk '
	BEGIN { top = 0 }
	/^<[^\/!]/ {
	    struct = substr($1, 2)
	    if (struct == "'"$struct"'") {
		print (top > 0 ? stack[top] : "")
                exit 0
	    }
	    stack[++top] = struct
	}
	/^<\// { top-- }
    '
    return 0
}

scramble_structs () {
    local unit within
    if [ "x$scramble_seed" = x ]; then
	scramble_seed=$corpus
    fi
    for unit in $scramble; do
	within=$(find_containing_struct $unit "$vrt_file")
	if [ $? != 0 ]; then
	    warn "Input VRT has no $unit structures specified with --scramble"
	elif [ "x$within" = x ]; then
	    warn "Cannot scramble top-level structures $unit"
	elif ! word_in "$unit" "sentence paragraph link"; then
	    warn "Scrambling $unit structures instead of the usual sentence, paragraph or link"
	fi
	if [ "x$within" != x ]; then
	    process_vrt $vrt_scramble --seed $scramble_seed \
		--unit $unit --within $within
	fi
    done
}

test_skip_scramble_structs () {
    [ "x$scramble" = x ] &&
    echo "not requested"
}

add_struct_ids () {
    local opts=
    local struct
    if [ "x$keep_struct_ids" = x ]; then
	opts=--force
    fi
    for struct in $add_struct_ids; do
	opts="$opts --structure=$struct"
    done
    process_vrt $vrt_add_struct_ids $opts
}

test_skip_add_struct_ids () {
    local struct
    local has_structs=
    if [ "x$add_struct_ids" = x ]; then
        echo "requested not to add"
        return
    fi
    for struct in $add_struct_ids; do
        if grep -q -s "^<$struct " "$vrt_file"; then
            has_structs=1
            break
        fi
    done
    if [ "$has_structs" != 1 ]; then
        echo "no structures ($(delimit ", " $add_struct_ids)) present"
        return
    fi
    # It would be nice if this could modify $add_struct_ids to
    # contain only the structures without ids, but the function is
    # run as a subprocess, so the change would not propagate to
    # the parent
    for struct in $add_struct_ids; do
        # FIXME (how?): The following also matches if an attribute
        # value ends in "id="
        if ! grep -m1 "^<$struct " "$vrt_file" | grep -q -s ' id="'; then
            return
        fi
    done
    echo "already present"
}

filter_new_attrs () {
    $cwb_describe_corpus -s $corpus > $tmp_prefix.corpusattrs 2> /dev/null
    if [ $? != 0 ]; then
	echo "$@"
    else
	# FIXME: Why does this put lemma and lemmacomp at the end,
	# whereas the other attributes are in the order in which they
	# are in the input?
	awk '
	    BEGIN {
		for (i = 1; i < ARGC; i++) { attrs[i] = ARGV[i] }
		delete ARGV
	    }
	    /^p-ATT/ { old_attrs[$2] = 1 }
	    END {
		for (i in attrs) {
		    attrname_bare = gensub (/\//, "", "g", attrs[i])
		    # Lemma needs to be recoded as lemmacomp if lemmacomp is
		    # not already present
		    if (! (attrname_bare in old_attrs) \
			|| (attrname_bare == "lemma" \
			    && ! ("lemmacomp" in old_attrs))) {
			print attrs[i]
		    }
		}
	    }' $@ < $tmp_prefix.corpusattrs
    fi
}

add_attrs_to_registry () {
    local structspecs structspec
    structspecs=$1
    # cwb_registry_add_posattr adds only non-existing attributes, so
    # it does not matter if $input_attrs contains attributes already
    # existing in the corpus.
    cwb_registry_add_posattr $corpus ${input_attrs///}
    for structspec in $structspecs; do
	# Remove the nesting depth
	structspec=${structspec/:[0-9]/}
	# Arguments: struct name followed by attr names
	cwb_registry_add_structattr $corpus ${structspec//+/ }
    done
    # If needed, move lemmacomp to immediately after lemma. This is
    # relevant when augmenting existing data: if the data has other
    # positional attributes after lemma, lemmacomp would come after
    # them all without this.
    cwb_registry_reorder_posattrs $corpus lemma lemmacomp
}

cwb_encode () {
    local featset_attrnums convert_chars_opts structnames reg_opt
    featset_attrnums=$(
	printf ${input_attrs// /\\n} |
	grep -n '/$' |
	cut -d: -f1 |
	tr '\n' ',' |
	sed -e 's/,$//'
    )
    convert_chars_opts=
    if [ "x$featset_attrnums" != "x" ]; then
	convert_chars_opts="--feature-set-attrs $featset_attrnums"
    fi
    echo_verb "  Inferring structural attributes from the VRT file"
    structnames=$(grep '^<' $vrt_file | run_cmd $vrt_list_struct_attrs)
    mkdir_perms $datadir
    reg_opt=
    # For new corpora, let cwb-encode generate the registry file
    if [ "x$augment_data" = x ]; then
	reg_opt="-R $cwb_regdir/$corpus"
    fi
    # $input_attrs contains "word" (unless --no-word-attribute), so
    # use "cwb-encode -p -" to avoid adding "word" twice
    run_cmd $vrt_convert_chars $convert_chars_opts \
	--feature-set-struct-attributes "$structnames" < $vrt_file |
    tee $tmp_prefix.tee |
    run_cmd $cwb_encode -d $datadir $reg_opt -p - \
	-xsB -c utf8 $(add_prefix "-P " $input_attrs) \
	$(add_prefix "-S " $structnames)
    # For existing corpora, add the new new attributes to the registry
    if [ "x$augment_data" != x ]; then
	add_attrs_to_registry "$structnames"
    fi
}

test_skip_cwb_encode () {
    # new_attrs is global, but it is initialized here for practical
    # reasons.
    new_attrs=$(filter_new_attrs "${input_attrs///}")
    [ "x$augment_data" = x ] &&
    [ "x$new_attrs" = x ] &&
    [ -s $cwb_regdir/$corpus ] &&
    echo "already encoded"
}

cwb_make () {
    run_cmd $cwb_make -r $cwb_regdir -g $filegroup -p 664 -M 2000 $corpus
}

test_skip_cwb_make () {
    [ "x$augment_data" = x ] &&
    [ "x$new_attrs" = x ] &&
    [ -s $datadir/word.crx ] &&
    echo "already done"
}

convert_timedata () {
    run_cmd $korp_convert_timedata --tsv-dir "$tsvdir" $verbose_opt \
	--corpus-root "$corpus_root" $corpus
}

test_skip_convert_timedata () {
    corpus_has_attr $corpus s text_timefrom &&
    [ -s $tsvdir/${corpus}_timedata.tsv.gz ] &&
    echo "already converted"
}

extract_info () {
    # --verbose would add the corpus id to the .info file which is not
    # desired.
    run_cmd $cwbdata_extract_info --tsv-dir "$tsvdir" $corpus > $datadir/.info
}

extract_lemgrams () {
    local lemgram_attrnum=$(word_index lex/ $input_attrs)
    run_cmd $vrt_extract_lemgrams --corpus-id $corpus --lemgram-field $lemgram_attrnum \
	$vrt_file |
    gzip > $tsvdir/${corpus}_lemgrams.tsv.gz
}

test_skip_extract_lemgrams () {
    if ! word_in lex/ "$input_attrs"; then
	echo "lemgrams not present"
    elif [ -s $tsvdir/${corpus}_lemgrams.tsv.gz ]; then
	echo "already extracted"
    fi
}

extract_wordpict_rels () {
    run_cmd $run_extract_rels --corpus-name $corpus \
	--input-fields "${input_attrs%/}" \
	--output-dir "$tsvdir" --relation-map "$wordpict_relmap" \
	--optimize-memory --no-tar \
	< $vrt_file
}

test_skip_extract_wordpict_rels () {
    local attr
    # Suffixes in word picture relation database file names
    local relfile_suffs=("" _dep_rel _head_rel _rel _sentences _strings)
    local suff
    local fname
    local missing_attrs=
    local pl=
    for attr in lemma pos deprel dephead ref; do
	if ! { word_in $attr "$input_attrs" ||
		word_in $attr/ "$input_attrs"; }
	then
            missing_attrs="$missing_attrs $attr"
	fi
    done
    if [ "x$missing_attrs" != x ]; then
        if [ "$(count_words $missing_attrs)" -gt 1 ]; then
            pl=s
        fi
        echo "no positional attribute$pl $(delimit ", " $missing_attrs)"
        return
    fi
    if [ "x$wordpicture" = x ]; then
	echo "requested not to extract"
        return
    fi
    # Requested to remake
    if [ "x$remake_wordpicture_data" != x ]; then
        rm -f $tsvdir/${corpus}_rels*.tsv.gz
        return
    fi
    # If any file does not exist or is empty (when uncompressed),
    # remake all
    for suff in "${relfile_suffs[@]}"; do
        fname=$tsvdir/${corpus}_rels$suff.tsv.gz
        if [ ! -r $fname ] || {
               [ "$(wc -c < $fname)" -lt 80 ] &&
                   [ "$(zcat $fname | wc -c)" = "0" ]; };
        then
            return
        fi
    done
    echo "already extracted"
}

add_name_attrs () {
    run_cmd $vrt_add_name_attrs $corpus @data @data
}

test_skip_add_name_attrs () {
    if [ "x$name_attrs" = x ]; then
	echo "requested not to add"
    elif ! word_in "nertag" "$input_attrs"; then
	echo "NER tags not present (positional attribute nertag)"
    elif corpus_has_attr $corpus s ne_ex; then
	echo "already present"
    fi
}

adjust_posattrs_comment () {
    process_vrt vrt_replace_posattr_names "$input_attrs"
}

test_skip_adjust_posattrs_comment () {
    [ "x$input_attrs" = "x$initial_vrt_posattrs" ] &&
	echo "positional attributes not changed"
}

make_corpus_package () {
    local extra_opts vrt_opt
    [ "x$korp_frontend_dir" != x ] &&
    extra_opts="$extra_opts --korp-frontend-dir=$korp_frontend_dir"
    [ "x$package_readme_file" != x ] &&
    extra_opts="--readme-file=$package_readme_file"
    [ "x$package_doc_dir" != x ] &&
    extra_opts="$extra_opts --doc-dir=$package_doc_dir"
    [ "x$package_doc_file" != x ] &&
    extra_opts="$extra_opts --doc-file=$package_doc_file"
    [ "x$package_script_dir" != x ] &&
    extra_opts="$extra_opts --script-dir=$package_script_dir"
    [ "x$package_script_file" != x ] &&
    extra_opts="$extra_opts --script-file=$package_script_file"
    [ "x$package_extra_dir" != x ] &&
    extra_opts="$extra_opts --extra-dir=$package_extra_dir"
    [ "x$package_extra_file" != x ] &&
    extra_opts="$extra_opts --extra-file=$package_extra_file"
    run_cmd gzip --no-name --force $vrt_file
    if [ "x$augment_data" = x ]; then
	vrt_opt="--vrt-file $vrt_file.gz"
    else
	vrt_opt="--update-vrt"
    fi
    run_cmd $korp_make_corpus_package --target-corpus-root /v/corpora \
	--corpus-root "$corpus_root" \
	--tsv-dir "$tsvdir" --database-format tsv --compress gzip \
	$vrt_opt $auth_opts $extra_opts $corpus
}

test_skip_make_corpus_package () {
    [ "x$make_package" = x ] &&
    echo "requested not to create"
}

import_database () {
    tsv_files="$(add_prefix $tsvdir/${corpus}_ lemgrams.tsv.gz timedata.tsv.gz timedata_date.tsv.gz)"
    if [ "x$wordpicture" != x ]; then
	tsv_files="$tsv_files $(echo $tsvdir/${corpus}_rels*.tsv.gz)"
    fi
    run_cmd $korp_mysql_import --prepare-tables --relations-format new \
	$tsv_files
}

test_skip_import_database () {
    [ "x$import_database" = x ] &&
    echo "not requested"
}


main () {
    echo_verb "Making Korp corpus $corpus:"
    # $top_stdout is used by run_cmd to output the command to the top
    # stdout even if the command is run in a pipeline.
    top_stdout=3
    exec 3> /dev/stdout
    set -o pipefail
    if [ "x$force" != x ]; then
        remove_existing_data
    fi
    run_stages
    exec 3>&-
    ensure_perms $tsvdir/* $vrtdir/* $datadir/* $cwb_regdir/$corpus 2> /dev/null
    echo_verb "Completed."
}


echo_verb $(date +'[%F %T]')
# FIXME: The format is not effective, since the formats used in inner
# time_cmd calls take overwrite the format (TIMEFORMAT environment
# variable).
time_cmd --format "- Total CPU time used: %U %R" main "$@"
echo_verb $(date +'[%F %T]')
