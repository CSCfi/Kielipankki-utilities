#! /usr/bin/env python3
# -*- mode: Python; -*-

from argparse import ArgumentParser
from itertools import groupby, count
from subprocess import Popen, PIPE, DEVNULL
from threading import Thread
import enum, os, re, sys, tempfile, traceback

# this thing is known variously as "mate tools" (though mate tools
# consist of other things, too), "anna" (for whatever motivation,
# nowhere to be found), apparently "is2", and "the parser" and certain
# locutions that describe or praise the parser.

WHATEVER = [ 'java', '-cp',
             '/proj/kieli/varpunen/mate-tools/anna-3-1.jar',
             'is2.parser.Parser',
             '-model', '/proj/kieli/varpunen/models/parser.model',
             '-test', '/dev/stdin'

             # extend with [ '-out', pipename ] at the point of Popen,
             # when a named-pipe name is at hand, because this version
             # of this thing writes its diagnostics in its stdout
]

# Let slip the first "Processing Sentence: 1 (32 ms/instance)".
# Quash the hundred thousand "2 (113 ms/instance)" that follow.
BREAKER = [ '/usr/bin/tr', '-s', r'\b', r'\n' ] # sigh
QUASHER = [ '/bin/grep', '-P', '-x', '-v', r'\d+ \(\d+ ms/instance\)' ]

VERSION = '0.2 (2018-06-25)'

parser = ArgumentParser(description = '''

Pass morphologically tagged word forms in a flat vrt document through
the parser of Mate-Tools using the model from Turku. Insert the
syntactic dependency analysis in new fields after the tag field. The
vrt document must have position names in a comment before any
content. (A "flat" vrt document has no markup or comment lines inside
sentence elements.)

''')

# TODO should make checks - cannot have spaces or < & > + and so.
def nametype(name): return name.encode('UTF-8')
def suffixtype(fix): return fix.encode('UTF-8')

parser.add_argument('infile', nargs = '?', metavar = 'file',
                    help = 'input file (default stdin)')
parser.add_argument('--out', '-o',
                    dest = 'outfile', metavar = 'file',
                    help = 'output file (default stdout)')
parser.add_argument('--in-place', '-i',
                    dest = 'inplace', action = 'store_true',
                    help = 'overwrite input file with output')
parser.add_argument('--backup', '-b', metavar = 'bak',
                    help = 'keep input file with suffix bak')
parser.add_argument('--word', '-w', metavar = 'name',
                    type = nametype, default = b'word',
                    help = 'input word-field name (default word)')
parser.add_argument('--tag', '-t', metavar = 'name',
                    type = nametype, default = b'pos',
                    help = 'input pos-tag-field name (default pos)')
parser.add_argument('--feat', '-f', metavar = 'name',
                    type = nametype, default = b'feat',
                    help = 'input feature-field name (default feat)')
parser.add_argument('--prefix', '-p', metavar = 'fix',
                    type = nametype, default = b'',
                    help = 'prefix to output-field names')
parser.add_argument('--suffix', '-s', metavar = 'fix',
                    type = suffixtype, default = b'',
                    help = 'suffix to output-field names')

noise_level = parser.add_mutually_exclusive_group()
noise_level.add_argument('--quiet', '-q', action = 'store_true',
                         help = 'quash all diagnostics from the parser')
noise_level.add_argument('--verbose', '-v', action = 'store_true',
                         help = 'watch parser report on every sentence')

parser.add_argument('--version', action = 'store_true',
                    help = 'print {} and exit'.format(VERSION))

# old values are passed unescaped to the underlying process,
# new values are inserted escaped to the output stream
bare, code = (b'&', b'<', b'>'), (b'&amp;', b'&lt;', b'&gt;')
def encm(m, d = dict(zip(bare, code))): return d[m.group()]
def decm(m, d = dict(zip(code, bare))): return d[m.group()]
def escape(value): return re.sub(b'[&<>]', encm, value)
def unescape(value): return re.sub(b'&(amp|lt|gt);', decm, value)

class BadData(Exception): pass # stack trace is just noise
class BadCode(Exception): pass # this cannot happen

class Kind(enum.Enum):
    # kind of line (group of them)
    meta = 1
    data = 2
    begin = 3
    names = 4
    comment = 5

def identify(line):
    # used by groupby to identify the kind of a line group
    if line.startswith(b'<!-- Positional attributes:'): return Kind.names
    if line.startswith(b'<!--'): return Kind.comment
    if line.startswith(b'<sentence'): return Kind.begin
    if line.startswith(b'<'): return Kind.meta
    return Kind.data

def combine(pipename, copy, out):
    '''Read whatever output (id TAB word TAB _ TAB pos ... msd TAB NL / NL)
    and flat vrt from the copy process. Insert dependency analysis
    from whatever to the vrt at the named position.

    This is run as a thread that consumes the two processes.

    '''

    try:
        # this blocks until the subprocess in main thread has opened
        # the named pipe for writing - what if it fails to do that?
        pipe = open(pipename, mode = 'br')
        implement_combine(pipe, copy, out)
    except BrokenPipeError:
        print(parser.prog + ':', 'in combine thread: Broken Pipe',
              file = sys.stderr)
    except StopIteration:
        # from next(response) when main thread got keyboard interruption
        print(parser.prog + ':', 'in combine thread: Stop Iteration',
              file = sys.stderr)
    except ValueError as exn:
        # sometimes keyboard interruption in main thread produces here
        # a readline of closed file
        print(parser.prog + ':', 'in combine thread: Value Error:', exn,
              file = sys.stderr)
    finally:
        # closing their stdouts should send whatever (behind pipe) and
        # copy the signal to shut down, right? and then the main
        # thread should get broken pipe to indicate that it can no
        # longer write to them?
        pipe.close() # no need to wait for it?
        copy.stdout.close() # no need to wait for it or something?

def implement_combine(pipe, copy, out):
    '''Thread may find pipe closed. (What now that it is a named pipe?)'''

    response = (tokens
                for isempty, tokens
                in groupby(pipe, bytes.isspace)
                if not isempty)
    
    mf = None # msd field index, after which insert new
    found = False
    for kind, group in groupby(copy.stdout, identify):

        if kind is not Kind.data: found = False
        if kind is Kind.begin: found = True

        if (kind is Kind.data) and found:
            for new, old in zip(next(response), group):
                [
                    ID, form, lemma, plemma,
                    pos, ppos, feat, pfeat,
                    dephead, pdephead, deprel, pdeprel,
                    fillpred, pred
                ] = new.rstrip(b'\n').split(b'\t')
                values = old.rstrip(b'\n').split(b'\t')
                values.insert(mf + 1, escape(pdeprel))
                values.insert(mf + 1, escape(pdephead))
                values.insert(mf + 1, escape(ID))
                out.write(b'\t'.join(values))
                out.write(b'\n')
            else:
                continue

        if kind is Kind.names:
            for line in group:
                mf = getpos(line, args.tag)
                out.write(line)
            else:
                continue

        for line in group:
            # print('DEBUG: catchall write')
            out.write(line)
        else:
            continue

def getpos(names, name):
    namelist = re.findall(br'[\w.+]+', names)[2:]
    try:
        return namelist.index(name)
    except ValueError:
        raise BadData('no such name: {}'.format(name.decode('UTF-8')))

def addnames(names, atname, *afternames):
    '''Build new name-line with afternames inserted after atname.'''
    new = re.findall(br'[\w.+]+', names)[2:]
    if atname not in new:
        raise BadData('no such positional attribute: {}'
                      .format(atname.decode('UTF-8')))
    for aftername in reversed(afternames):
        if aftername in new:
            raise BadData('positional attribute already in use: {}'
                          .format(aftername.decode('UTF-8')))
        else:
            new.insert(new.index(atname) + 1, aftername)
    return b' '.join([b'<!-- Positional attributes:'] + new + [b'-->\n'])

def getword(line, pos): # needs to be renamed
    return line.rstrip(b'\n').split(b'\t')[pos]

def wrap_main():
    
    if (args.backup is not None) and '/' in args.backup:
        print('usage: --backup suffix cannot contain /', file = sys.stderr)
        exit(1)

    if (args.backup is not None) and not args.backup:
        print('usage: --backup suffix cannot be empty', file = sys.stderr)
        exit(1)

    if (args.backup is not None) and not args.inplace:
        print('usage: --backup requires --in-place', file = sys.stderr)
        exit(1)

    if args.inplace and (args.infile is None):
        print('usage: --in-place requires input file', file = sys.stderr)
        exit(1)

    if args.inplace and (args.outfile is not None):
        print('usage: --in-place not allowed with --out', file = sys.stderr)
        exit(1)

    if (args.outfile is not None) and os.path.exists(args.outfile):
        # easier to check this than that output file is different than
        # input file, though it be annoying when overwrite is wanted
        print('usage: --out file must not exist', file = sys.stderr)
        exit(1)

    try:
        if args.inplace or (args.outfile is not None):
            head, tail = os.path.split(args.infile
                                       if args.inplace
                                       else args.outfile)
            # 2018-09-13 mkstemp failed - apparently this path
            # had not been tested TODO
            fd, temp = tempfile.mkstemp(dir = head, prefix = tail)
            os.close(fd)
        else:
            temp = None

        with ((args.infile and open(args.infile, mode = 'br'))
              or sys.stdin.buffer) as inf:
            with ((temp and open(temp, mode = 'bw'))
                  or sys.stdout.buffer) as ouf:
                status = main(inf, ouf)

        args.backup and os.rename(args.infile, args.infile + args.backup)
        args.inplace and os.rename(temp, args.infile)
        args.outfile and os.rename(temp, args.outfile)
        exit(status)
    except IOError as exn:
        print(exn, file = sys.stderr)
        exit(1)

def main(inf, ouf):
    temp = tempfile.mkdtemp(prefix = 'vrt.')
    pipename = os.path.join(temp, 'tdpalpha')
    os.mkfifo(pipename)
    print(parser.prog + ': creating {}'
          .format(pipename), file = sys.stderr)

    breaker = ( None
                if args.quiet else
                Popen(BREAKER, stdin = PIPE, stdout = sys.stderr.buffer)
                if args.verbose else
                Popen(BREAKER, stdin = PIPE, stdout = PIPE) )

    quasher = ( None
                if (args.quiet or args.verbose) else
                Popen(QUASHER,
                      stdin = breaker.stdout,
                      stdout = sys.stderr.buffer) )

    # somewhere here should close some standard streams to have
    # eventual broken pipes have the intended effect, right? no?
    # breaker.stdout when it is the PIPE to quasher, presumably

    with Popen(WHATEVER + [ '-out', pipename ],
               stdin = PIPE,
               stdout = (breaker.stdin if breaker else DEVNULL),
               stderr = sys.stderr.buffer) as whatever:
        with Popen(['cat'],
                   stdin = PIPE,
                   stdout = PIPE,
                   stderr = sys.stderr.buffer) as copy:

            # is this a "useless use of cat"?

            t = Thread(target = combine, args = (pipename, copy, ouf))
            t.start()

            status = 1
            try:
                implement_main(inf, whatever, copy)
                status = 0
            except BadData as exn:
                print(parser.prog + ':', exn, file = sys.stderr)
            except BrokenPipeError as exn:
                # when combine thread gets broken pipe, it closes the
                # output side of hunpos and copy, then they close and
                # this thread gets broken pipe - right?
                print(parser.prog + ':', 'in main thread: Broken Pipe',
                      file = sys.stderr)
            except KeyboardInterrupt as exn:
                print(parser.prog + ':', 'in main thread: Keyboard Interrupt',
                      file = sys.stderr)
            except Exception as exn:
                print(traceback.format_exc(), file = sys.stderr)

            whatever.stdin.close()
            copy.stdin.close()
            t.join()
            print(parser.prog + ': removing {}'
                  .format(pipename), file = sys.stderr)
            os.remove(pipename)
            os.rmdir(temp)

            # what about breaker and quasher, if any?

            return status

def implement_main(inf, whatever, copy):

    # each "word" and "tag" go to whatever, with empty line after
    # sentence; everything but empty goes to copy, with new "id",
    # "dephead", "deprel" (or such) in names

    wf, tf, ff = None, None, None # word, tag, feat positions
    found = False
    def isnotspace(line): return not line.isspace()
    for kind, group in groupby(filter(isnotspace, inf), identify):

        if kind is not Kind.data: found = False
        if kind is Kind.begin: found = True

        if kind is Kind.data and found:
            if wf is None:
                raise BadData('error: token before field names')
            for k, line in enumerate(group, start = 1):
                # print('DEBUG: sending token')
                # format for the whatever parser is CoNLL'09:
                # ID FORM LEMMA PLEMMA POS PPOS FEAT PFEAT
                # HEAD PHEAD DEPREL PDEPREL FILLPRED PRED APREDs
                # (er, any number of APRED1, APRED2, ...)
                # to guess where the input should be - ID, FORM,
                # POS, FEAT, right? but does the parser conform?

                # ID tab
                whatever.stdin.write(str(k).encode('UTF-8'))
                whatever.stdin.write(b'\t')
                # FORM tab LEMMA tab PLEMMA tab
                whatever.stdin.write(unescape(getword(line, wf))) # rename getword
                whatever.stdin.write(b'\t_\t_\t')
                # POS tab PPOS tab
                whatever.stdin.write(unescape(getword(line, tf)))
                whatever.stdin.write(b'\t_\t')
                # FEAT tab PFEAT tab
                whatever.stdin.write(unescape(getword(line, ff)))
                whatever.stdin.write(b'\t_\t')
                # HEAD tab PHEAD tab DEPREL tab PDEPREL tab
                whatever.stdin.write(b'_\t_\t_\t_\t')
                # FILLPRED tab PRED nl
                whatever.stdin.write(b'_\t_\n')
                copy.stdin.write(line)
            else:
                whatever.stdin.write(b'\n')
                whatever.stdin.flush()
                copy.stdin.flush()
                continue

        if kind is Kind.begin:
            for line in group: copy.stdin.write(line)
            continue

        if kind is Kind.meta:
            for line in group: copy.stdin.write(line)
            continue

        if kind is Kind.data:
            for line in group: copy.stdin.write(line)
            continue

        if kind is Kind.names:
            for line in group:
                wf = getpos(line, args.word)
                tf = getpos(line, args.tag)
                ff = getpos(line, args.feat)
                copy.stdin.write(addnames(line, args.tag,
                                          args.prefix + b'id' + args.suffix,
                                          args.prefix + b'head' + args.suffix,
                                          args.prefix + b'rel' + args.suffix))
            else:
                continue

        if kind is Kind.comment:
            for line in group: copy.stdin.write(line)
            continue

        raise BadCode('this cannot happen')

if __name__ == '__main__':
    args = parser.parse_args()
    if args.version:
        print(VERSION)
    else:
        wrap_main()
